{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "diabetesdetection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNTl1dH7LT2d7vKCjBgRSeq"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC6yRJN95rZ6",
        "colab_type": "text"
      },
      "source": [
        "Import the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaFi4fW95glr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dec2a319-3bdf-4612-8d64-e4a088300b08"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt7ZJIFy63Uf",
        "colab_type": "text"
      },
      "source": [
        "Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftioJ8Kf652Q",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "3184338b-f59b-4d9d-d5fb-93e661e3f7d9"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bb522e0a-2b5f-4d10-bb2a-2ff1a2d75392\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-bb522e0a-2b5f-4d10-bb2a-2ff1a2d75392\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving diabetes.csv to diabetes.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KjCDCDd7MO2",
        "colab_type": "text"
      },
      "source": [
        "Store the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpygZCF-7PPE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "29786bd7-698e-4ce3-b336-4d816360e2bc"
      },
      "source": [
        "df = pd.read_csv('diabetes.csv')\n",
        "\n",
        "# Print the first 7 rows of data\n",
        "df.head(7)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>116</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.6</td>\n",
              "      <td>0.201</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>78</td>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>88</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.248</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "5            5      116             74  ...                     0.201   30        0\n",
              "6            3       78             50  ...                     0.248   26        1\n",
              "\n",
              "[7 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENkWrX9p7fte",
        "colab_type": "text"
      },
      "source": [
        "Get the shape of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqchGkJG7hzZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "812d7376-4432-4dd1-902f-cc67d0b13952"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRj3b3Kd7mcR",
        "colab_type": "text"
      },
      "source": [
        "Check for dupclicates and remove them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6UNlLtS7qAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.drop_duplicates(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rZg8f8X7vyB",
        "colab_type": "text"
      },
      "source": [
        "Show the new shape of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlR8cY2M7yrr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d01226d7-e603-4acd-a994-03aec934d45e"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRo9DCiq70hB",
        "colab_type": "text"
      },
      "source": [
        "Show the number of missing data points for each column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSEiOwYk740Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "3ac2e006-c45f-4e69-81c8-dcd765a91632"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pregnancies                 0\n",
              "Glucose                     0\n",
              "BloodPressure               0\n",
              "SkinThickness               0\n",
              "Insulin                     0\n",
              "BMI                         0\n",
              "DiabetesPedigreeFunction    0\n",
              "Age                         0\n",
              "Outcome                     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgofXH6C8AZG",
        "colab_type": "text"
      },
      "source": [
        "Convert the data into an array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgQidlMA8DP1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "18143a1f-3f6f-4362-b1b1-d18d7e339d86"
      },
      "source": [
        "dataset = df.values\n",
        "dataset"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nV3Bmxyt8Mzw",
        "colab_type": "text"
      },
      "source": [
        "Get all of the rows from the first 8 columns of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIO44-2D8SxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = dataset[:, 0:8] # independant dataset\n",
        "y = dataset[:, 8] # dependant dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rx3muG68lgD",
        "colab_type": "text"
      },
      "source": [
        "Process the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5wJqz328nKj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "0b7af293-f7fd-4f81-adfd-24c94f7fd0c2"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)\n",
        "\n",
        "X_scale"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
              "        0.48333333],\n",
              "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
              "        0.16666667],\n",
              "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
              "        0.18333333],\n",
              "       ...,\n",
              "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
              "        0.15      ],\n",
              "       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
              "        0.43333333],\n",
              "       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
              "        0.03333333]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lkpRX_A9E-q",
        "colab_type": "text"
      },
      "source": [
        "Split the data into 80% training and 20% testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkS4G3ul9JTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_scale, y, test_size=0.2, random_state=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiyTWQZu9Yg6",
        "colab_type": "text"
      },
      "source": [
        "Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0uZsLph9amd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "                    Dense(12, activation='relu', input_shape=(8,)), \n",
        "                    Dense(15, activation='relu'),\n",
        "                    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4JxV4OR96vX",
        "colab_type": "text"
      },
      "source": [
        "Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3FmEmWR989w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(\n",
        "    optimizer = 'sgd',\n",
        "    loss = 'binary_crossentropy',\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehlV10Q_-QDg",
        "colab_type": "text"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_nuH6bV-R4c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bcab76cd-0fd4-4291-ba59-188b4ca4d4b8"
      },
      "source": [
        "hist = model.fit(x_train, y_train, batch_size=57, epochs=1000, validation_split=0.2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 491 samples, validate on 123 samples\n",
            "Epoch 1/1000\n",
            "491/491 [==============================] - 0s 640us/step - loss: 0.6898 - accuracy: 0.6151 - val_loss: 0.6872 - val_accuracy: 0.6260\n",
            "Epoch 2/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6870 - accuracy: 0.6171 - val_loss: 0.6844 - val_accuracy: 0.6504\n",
            "Epoch 3/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6843 - accuracy: 0.6415 - val_loss: 0.6818 - val_accuracy: 0.6667\n",
            "Epoch 4/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6818 - accuracy: 0.6436 - val_loss: 0.6795 - val_accuracy: 0.6504\n",
            "Epoch 5/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6794 - accuracy: 0.6497 - val_loss: 0.6771 - val_accuracy: 0.6504\n",
            "Epoch 6/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6771 - accuracy: 0.6497 - val_loss: 0.6749 - val_accuracy: 0.6585\n",
            "Epoch 7/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6749 - accuracy: 0.6497 - val_loss: 0.6728 - val_accuracy: 0.6585\n",
            "Epoch 8/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6729 - accuracy: 0.6497 - val_loss: 0.6708 - val_accuracy: 0.6504\n",
            "Epoch 9/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6709 - accuracy: 0.6477 - val_loss: 0.6689 - val_accuracy: 0.6504\n",
            "Epoch 10/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6692 - accuracy: 0.6477 - val_loss: 0.6672 - val_accuracy: 0.6504\n",
            "Epoch 11/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6675 - accuracy: 0.6477 - val_loss: 0.6655 - val_accuracy: 0.6504\n",
            "Epoch 12/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6660 - accuracy: 0.6477 - val_loss: 0.6639 - val_accuracy: 0.6504\n",
            "Epoch 13/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6645 - accuracy: 0.6477 - val_loss: 0.6625 - val_accuracy: 0.6504\n",
            "Epoch 14/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6631 - accuracy: 0.6477 - val_loss: 0.6613 - val_accuracy: 0.6504\n",
            "Epoch 15/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6619 - accuracy: 0.6477 - val_loss: 0.6600 - val_accuracy: 0.6504\n",
            "Epoch 16/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6608 - accuracy: 0.6477 - val_loss: 0.6589 - val_accuracy: 0.6504\n",
            "Epoch 17/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6597 - accuracy: 0.6477 - val_loss: 0.6578 - val_accuracy: 0.6504\n",
            "Epoch 18/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6586 - accuracy: 0.6477 - val_loss: 0.6567 - val_accuracy: 0.6504\n",
            "Epoch 19/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6576 - accuracy: 0.6477 - val_loss: 0.6558 - val_accuracy: 0.6504\n",
            "Epoch 20/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6567 - accuracy: 0.6477 - val_loss: 0.6549 - val_accuracy: 0.6504\n",
            "Epoch 21/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6558 - accuracy: 0.6477 - val_loss: 0.6541 - val_accuracy: 0.6504\n",
            "Epoch 22/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6550 - accuracy: 0.6477 - val_loss: 0.6533 - val_accuracy: 0.6504\n",
            "Epoch 23/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6543 - accuracy: 0.6477 - val_loss: 0.6526 - val_accuracy: 0.6504\n",
            "Epoch 24/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6536 - accuracy: 0.6477 - val_loss: 0.6519 - val_accuracy: 0.6504\n",
            "Epoch 25/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6530 - accuracy: 0.6477 - val_loss: 0.6513 - val_accuracy: 0.6504\n",
            "Epoch 26/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6524 - accuracy: 0.6477 - val_loss: 0.6507 - val_accuracy: 0.6504\n",
            "Epoch 27/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6519 - accuracy: 0.6477 - val_loss: 0.6502 - val_accuracy: 0.6504\n",
            "Epoch 28/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6514 - accuracy: 0.6477 - val_loss: 0.6497 - val_accuracy: 0.6504\n",
            "Epoch 29/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6509 - accuracy: 0.6477 - val_loss: 0.6493 - val_accuracy: 0.6504\n",
            "Epoch 30/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6505 - accuracy: 0.6477 - val_loss: 0.6488 - val_accuracy: 0.6504\n",
            "Epoch 31/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6500 - accuracy: 0.6477 - val_loss: 0.6484 - val_accuracy: 0.6504\n",
            "Epoch 32/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6496 - accuracy: 0.6477 - val_loss: 0.6480 - val_accuracy: 0.6504\n",
            "Epoch 33/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6492 - accuracy: 0.6477 - val_loss: 0.6476 - val_accuracy: 0.6504\n",
            "Epoch 34/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6488 - accuracy: 0.6477 - val_loss: 0.6473 - val_accuracy: 0.6504\n",
            "Epoch 35/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6485 - accuracy: 0.6477 - val_loss: 0.6470 - val_accuracy: 0.6504\n",
            "Epoch 36/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6482 - accuracy: 0.6477 - val_loss: 0.6466 - val_accuracy: 0.6504\n",
            "Epoch 37/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6479 - accuracy: 0.6477 - val_loss: 0.6463 - val_accuracy: 0.6504\n",
            "Epoch 38/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.6476 - accuracy: 0.6477 - val_loss: 0.6460 - val_accuracy: 0.6504\n",
            "Epoch 39/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.6474 - accuracy: 0.6477 - val_loss: 0.6457 - val_accuracy: 0.6504\n",
            "Epoch 40/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6471 - accuracy: 0.6477 - val_loss: 0.6455 - val_accuracy: 0.6504\n",
            "Epoch 41/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.6469 - accuracy: 0.6477 - val_loss: 0.6453 - val_accuracy: 0.6504\n",
            "Epoch 42/1000\n",
            "491/491 [==============================] - 0s 44us/step - loss: 0.6467 - accuracy: 0.6477 - val_loss: 0.6450 - val_accuracy: 0.6504\n",
            "Epoch 43/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6465 - accuracy: 0.6477 - val_loss: 0.6448 - val_accuracy: 0.6504\n",
            "Epoch 44/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6463 - accuracy: 0.6477 - val_loss: 0.6446 - val_accuracy: 0.6504\n",
            "Epoch 45/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6461 - accuracy: 0.6477 - val_loss: 0.6444 - val_accuracy: 0.6504\n",
            "Epoch 46/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6460 - accuracy: 0.6477 - val_loss: 0.6442 - val_accuracy: 0.6504\n",
            "Epoch 47/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6458 - accuracy: 0.6477 - val_loss: 0.6440 - val_accuracy: 0.6504\n",
            "Epoch 48/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6456 - accuracy: 0.6477 - val_loss: 0.6438 - val_accuracy: 0.6504\n",
            "Epoch 49/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6454 - accuracy: 0.6477 - val_loss: 0.6436 - val_accuracy: 0.6504\n",
            "Epoch 50/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6452 - accuracy: 0.6477 - val_loss: 0.6434 - val_accuracy: 0.6504\n",
            "Epoch 51/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6451 - accuracy: 0.6477 - val_loss: 0.6432 - val_accuracy: 0.6504\n",
            "Epoch 52/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6449 - accuracy: 0.6477 - val_loss: 0.6431 - val_accuracy: 0.6504\n",
            "Epoch 53/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6448 - accuracy: 0.6477 - val_loss: 0.6430 - val_accuracy: 0.6504\n",
            "Epoch 54/1000\n",
            "491/491 [==============================] - 0s 48us/step - loss: 0.6448 - accuracy: 0.6477 - val_loss: 0.6428 - val_accuracy: 0.6504\n",
            "Epoch 55/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6446 - accuracy: 0.6477 - val_loss: 0.6427 - val_accuracy: 0.6504\n",
            "Epoch 56/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6444 - accuracy: 0.6477 - val_loss: 0.6426 - val_accuracy: 0.6504\n",
            "Epoch 57/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6443 - accuracy: 0.6477 - val_loss: 0.6424 - val_accuracy: 0.6504\n",
            "Epoch 58/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6442 - accuracy: 0.6477 - val_loss: 0.6423 - val_accuracy: 0.6504\n",
            "Epoch 59/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6441 - accuracy: 0.6477 - val_loss: 0.6422 - val_accuracy: 0.6504\n",
            "Epoch 60/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6439 - accuracy: 0.6477 - val_loss: 0.6420 - val_accuracy: 0.6504\n",
            "Epoch 61/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6438 - accuracy: 0.6477 - val_loss: 0.6419 - val_accuracy: 0.6504\n",
            "Epoch 62/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6437 - accuracy: 0.6477 - val_loss: 0.6418 - val_accuracy: 0.6504\n",
            "Epoch 63/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.6436 - accuracy: 0.6477 - val_loss: 0.6417 - val_accuracy: 0.6504\n",
            "Epoch 64/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6435 - accuracy: 0.6477 - val_loss: 0.6416 - val_accuracy: 0.6504\n",
            "Epoch 65/1000\n",
            "491/491 [==============================] - 0s 48us/step - loss: 0.6434 - accuracy: 0.6477 - val_loss: 0.6415 - val_accuracy: 0.6504\n",
            "Epoch 66/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6433 - accuracy: 0.6477 - val_loss: 0.6414 - val_accuracy: 0.6504\n",
            "Epoch 67/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6432 - accuracy: 0.6477 - val_loss: 0.6413 - val_accuracy: 0.6504\n",
            "Epoch 68/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6431 - accuracy: 0.6477 - val_loss: 0.6412 - val_accuracy: 0.6504\n",
            "Epoch 69/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6430 - accuracy: 0.6477 - val_loss: 0.6411 - val_accuracy: 0.6504\n",
            "Epoch 70/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6429 - accuracy: 0.6477 - val_loss: 0.6410 - val_accuracy: 0.6504\n",
            "Epoch 71/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6428 - accuracy: 0.6477 - val_loss: 0.6409 - val_accuracy: 0.6504\n",
            "Epoch 72/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6427 - accuracy: 0.6477 - val_loss: 0.6408 - val_accuracy: 0.6504\n",
            "Epoch 73/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6426 - accuracy: 0.6477 - val_loss: 0.6407 - val_accuracy: 0.6504\n",
            "Epoch 74/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.6425 - accuracy: 0.6477 - val_loss: 0.6406 - val_accuracy: 0.6504\n",
            "Epoch 75/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6424 - accuracy: 0.6477 - val_loss: 0.6406 - val_accuracy: 0.6504\n",
            "Epoch 76/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6423 - accuracy: 0.6477 - val_loss: 0.6405 - val_accuracy: 0.6504\n",
            "Epoch 77/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6422 - accuracy: 0.6477 - val_loss: 0.6404 - val_accuracy: 0.6504\n",
            "Epoch 78/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6421 - accuracy: 0.6477 - val_loss: 0.6403 - val_accuracy: 0.6504\n",
            "Epoch 79/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6420 - accuracy: 0.6477 - val_loss: 0.6402 - val_accuracy: 0.6504\n",
            "Epoch 80/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6419 - accuracy: 0.6477 - val_loss: 0.6402 - val_accuracy: 0.6504\n",
            "Epoch 81/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6419 - accuracy: 0.6477 - val_loss: 0.6401 - val_accuracy: 0.6504\n",
            "Epoch 82/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6418 - accuracy: 0.6477 - val_loss: 0.6400 - val_accuracy: 0.6504\n",
            "Epoch 83/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6417 - accuracy: 0.6477 - val_loss: 0.6400 - val_accuracy: 0.6504\n",
            "Epoch 84/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6416 - accuracy: 0.6477 - val_loss: 0.6399 - val_accuracy: 0.6504\n",
            "Epoch 85/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6415 - accuracy: 0.6477 - val_loss: 0.6398 - val_accuracy: 0.6504\n",
            "Epoch 86/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6415 - accuracy: 0.6477 - val_loss: 0.6398 - val_accuracy: 0.6504\n",
            "Epoch 87/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6413 - accuracy: 0.6477 - val_loss: 0.6397 - val_accuracy: 0.6504\n",
            "Epoch 88/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6413 - accuracy: 0.6477 - val_loss: 0.6396 - val_accuracy: 0.6504\n",
            "Epoch 89/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6412 - accuracy: 0.6477 - val_loss: 0.6396 - val_accuracy: 0.6504\n",
            "Epoch 90/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6412 - accuracy: 0.6477 - val_loss: 0.6395 - val_accuracy: 0.6504\n",
            "Epoch 91/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6411 - accuracy: 0.6477 - val_loss: 0.6394 - val_accuracy: 0.6504\n",
            "Epoch 92/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6409 - accuracy: 0.6477 - val_loss: 0.6394 - val_accuracy: 0.6504\n",
            "Epoch 93/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6409 - accuracy: 0.6477 - val_loss: 0.6393 - val_accuracy: 0.6504\n",
            "Epoch 94/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6408 - accuracy: 0.6477 - val_loss: 0.6392 - val_accuracy: 0.6504\n",
            "Epoch 95/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6407 - accuracy: 0.6477 - val_loss: 0.6392 - val_accuracy: 0.6504\n",
            "Epoch 96/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6406 - accuracy: 0.6477 - val_loss: 0.6391 - val_accuracy: 0.6504\n",
            "Epoch 97/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6406 - accuracy: 0.6477 - val_loss: 0.6390 - val_accuracy: 0.6504\n",
            "Epoch 98/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6405 - accuracy: 0.6477 - val_loss: 0.6390 - val_accuracy: 0.6504\n",
            "Epoch 99/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6404 - accuracy: 0.6477 - val_loss: 0.6389 - val_accuracy: 0.6504\n",
            "Epoch 100/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6403 - accuracy: 0.6477 - val_loss: 0.6388 - val_accuracy: 0.6504\n",
            "Epoch 101/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6402 - accuracy: 0.6477 - val_loss: 0.6388 - val_accuracy: 0.6504\n",
            "Epoch 102/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6401 - accuracy: 0.6477 - val_loss: 0.6387 - val_accuracy: 0.6504\n",
            "Epoch 103/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6400 - accuracy: 0.6477 - val_loss: 0.6386 - val_accuracy: 0.6504\n",
            "Epoch 104/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6400 - accuracy: 0.6477 - val_loss: 0.6385 - val_accuracy: 0.6504\n",
            "Epoch 105/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6399 - accuracy: 0.6477 - val_loss: 0.6384 - val_accuracy: 0.6504\n",
            "Epoch 106/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6398 - accuracy: 0.6477 - val_loss: 0.6383 - val_accuracy: 0.6504\n",
            "Epoch 107/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6397 - accuracy: 0.6477 - val_loss: 0.6382 - val_accuracy: 0.6504\n",
            "Epoch 108/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6396 - accuracy: 0.6477 - val_loss: 0.6382 - val_accuracy: 0.6504\n",
            "Epoch 109/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6396 - accuracy: 0.6477 - val_loss: 0.6381 - val_accuracy: 0.6504\n",
            "Epoch 110/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6394 - accuracy: 0.6477 - val_loss: 0.6380 - val_accuracy: 0.6504\n",
            "Epoch 111/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6393 - accuracy: 0.6477 - val_loss: 0.6379 - val_accuracy: 0.6504\n",
            "Epoch 112/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6393 - accuracy: 0.6477 - val_loss: 0.6378 - val_accuracy: 0.6504\n",
            "Epoch 113/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6392 - accuracy: 0.6477 - val_loss: 0.6377 - val_accuracy: 0.6504\n",
            "Epoch 114/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.6391 - accuracy: 0.6477 - val_loss: 0.6376 - val_accuracy: 0.6504\n",
            "Epoch 115/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6390 - accuracy: 0.6477 - val_loss: 0.6375 - val_accuracy: 0.6504\n",
            "Epoch 116/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6389 - accuracy: 0.6477 - val_loss: 0.6374 - val_accuracy: 0.6504\n",
            "Epoch 117/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6388 - accuracy: 0.6477 - val_loss: 0.6373 - val_accuracy: 0.6504\n",
            "Epoch 118/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6387 - accuracy: 0.6477 - val_loss: 0.6372 - val_accuracy: 0.6504\n",
            "Epoch 119/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6386 - accuracy: 0.6477 - val_loss: 0.6372 - val_accuracy: 0.6504\n",
            "Epoch 120/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6385 - accuracy: 0.6477 - val_loss: 0.6371 - val_accuracy: 0.6504\n",
            "Epoch 121/1000\n",
            "491/491 [==============================] - 0s 44us/step - loss: 0.6384 - accuracy: 0.6477 - val_loss: 0.6370 - val_accuracy: 0.6504\n",
            "Epoch 122/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6382 - accuracy: 0.6477 - val_loss: 0.6369 - val_accuracy: 0.6504\n",
            "Epoch 123/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6382 - accuracy: 0.6477 - val_loss: 0.6368 - val_accuracy: 0.6504\n",
            "Epoch 124/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6380 - accuracy: 0.6477 - val_loss: 0.6367 - val_accuracy: 0.6504\n",
            "Epoch 125/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6380 - accuracy: 0.6477 - val_loss: 0.6366 - val_accuracy: 0.6504\n",
            "Epoch 126/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6379 - accuracy: 0.6477 - val_loss: 0.6365 - val_accuracy: 0.6504\n",
            "Epoch 127/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.6378 - accuracy: 0.6477 - val_loss: 0.6364 - val_accuracy: 0.6504\n",
            "Epoch 128/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6376 - accuracy: 0.6477 - val_loss: 0.6363 - val_accuracy: 0.6504\n",
            "Epoch 129/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6375 - accuracy: 0.6477 - val_loss: 0.6362 - val_accuracy: 0.6504\n",
            "Epoch 130/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6374 - accuracy: 0.6477 - val_loss: 0.6361 - val_accuracy: 0.6504\n",
            "Epoch 131/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6373 - accuracy: 0.6477 - val_loss: 0.6360 - val_accuracy: 0.6504\n",
            "Epoch 132/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6372 - accuracy: 0.6477 - val_loss: 0.6359 - val_accuracy: 0.6504\n",
            "Epoch 133/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6371 - accuracy: 0.6477 - val_loss: 0.6358 - val_accuracy: 0.6504\n",
            "Epoch 134/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6370 - accuracy: 0.6477 - val_loss: 0.6357 - val_accuracy: 0.6504\n",
            "Epoch 135/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6369 - accuracy: 0.6477 - val_loss: 0.6356 - val_accuracy: 0.6504\n",
            "Epoch 136/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6367 - accuracy: 0.6477 - val_loss: 0.6355 - val_accuracy: 0.6504\n",
            "Epoch 137/1000\n",
            "491/491 [==============================] - 0s 48us/step - loss: 0.6366 - accuracy: 0.6477 - val_loss: 0.6354 - val_accuracy: 0.6504\n",
            "Epoch 138/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6365 - accuracy: 0.6477 - val_loss: 0.6352 - val_accuracy: 0.6504\n",
            "Epoch 139/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6364 - accuracy: 0.6477 - val_loss: 0.6351 - val_accuracy: 0.6504\n",
            "Epoch 140/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6362 - accuracy: 0.6477 - val_loss: 0.6350 - val_accuracy: 0.6504\n",
            "Epoch 141/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6361 - accuracy: 0.6477 - val_loss: 0.6349 - val_accuracy: 0.6504\n",
            "Epoch 142/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.6360 - accuracy: 0.6477 - val_loss: 0.6348 - val_accuracy: 0.6504\n",
            "Epoch 143/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6359 - accuracy: 0.6477 - val_loss: 0.6347 - val_accuracy: 0.6504\n",
            "Epoch 144/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6358 - accuracy: 0.6477 - val_loss: 0.6346 - val_accuracy: 0.6504\n",
            "Epoch 145/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6357 - accuracy: 0.6477 - val_loss: 0.6344 - val_accuracy: 0.6504\n",
            "Epoch 146/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6355 - accuracy: 0.6477 - val_loss: 0.6343 - val_accuracy: 0.6504\n",
            "Epoch 147/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6354 - accuracy: 0.6477 - val_loss: 0.6342 - val_accuracy: 0.6504\n",
            "Epoch 148/1000\n",
            "491/491 [==============================] - 0s 45us/step - loss: 0.6353 - accuracy: 0.6477 - val_loss: 0.6341 - val_accuracy: 0.6504\n",
            "Epoch 149/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6352 - accuracy: 0.6477 - val_loss: 0.6340 - val_accuracy: 0.6504\n",
            "Epoch 150/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6350 - accuracy: 0.6477 - val_loss: 0.6338 - val_accuracy: 0.6504\n",
            "Epoch 151/1000\n",
            "491/491 [==============================] - 0s 45us/step - loss: 0.6349 - accuracy: 0.6477 - val_loss: 0.6337 - val_accuracy: 0.6504\n",
            "Epoch 152/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6348 - accuracy: 0.6477 - val_loss: 0.6336 - val_accuracy: 0.6504\n",
            "Epoch 153/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6346 - accuracy: 0.6477 - val_loss: 0.6335 - val_accuracy: 0.6504\n",
            "Epoch 154/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6345 - accuracy: 0.6477 - val_loss: 0.6333 - val_accuracy: 0.6504\n",
            "Epoch 155/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.6344 - accuracy: 0.6477 - val_loss: 0.6332 - val_accuracy: 0.6504\n",
            "Epoch 156/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6342 - accuracy: 0.6477 - val_loss: 0.6331 - val_accuracy: 0.6504\n",
            "Epoch 157/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6340 - accuracy: 0.6477 - val_loss: 0.6329 - val_accuracy: 0.6504\n",
            "Epoch 158/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6339 - accuracy: 0.6477 - val_loss: 0.6328 - val_accuracy: 0.6504\n",
            "Epoch 159/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6337 - accuracy: 0.6477 - val_loss: 0.6326 - val_accuracy: 0.6504\n",
            "Epoch 160/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.6336 - accuracy: 0.6477 - val_loss: 0.6325 - val_accuracy: 0.6504\n",
            "Epoch 161/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6334 - accuracy: 0.6477 - val_loss: 0.6323 - val_accuracy: 0.6504\n",
            "Epoch 162/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6333 - accuracy: 0.6477 - val_loss: 0.6322 - val_accuracy: 0.6504\n",
            "Epoch 163/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6331 - accuracy: 0.6477 - val_loss: 0.6320 - val_accuracy: 0.6504\n",
            "Epoch 164/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6330 - accuracy: 0.6477 - val_loss: 0.6319 - val_accuracy: 0.6504\n",
            "Epoch 165/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6328 - accuracy: 0.6477 - val_loss: 0.6317 - val_accuracy: 0.6504\n",
            "Epoch 166/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6326 - accuracy: 0.6477 - val_loss: 0.6316 - val_accuracy: 0.6504\n",
            "Epoch 167/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6325 - accuracy: 0.6477 - val_loss: 0.6314 - val_accuracy: 0.6504\n",
            "Epoch 168/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6323 - accuracy: 0.6477 - val_loss: 0.6313 - val_accuracy: 0.6504\n",
            "Epoch 169/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6321 - accuracy: 0.6477 - val_loss: 0.6311 - val_accuracy: 0.6504\n",
            "Epoch 170/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6320 - accuracy: 0.6477 - val_loss: 0.6310 - val_accuracy: 0.6504\n",
            "Epoch 171/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6319 - accuracy: 0.6477 - val_loss: 0.6308 - val_accuracy: 0.6504\n",
            "Epoch 172/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6317 - accuracy: 0.6477 - val_loss: 0.6307 - val_accuracy: 0.6504\n",
            "Epoch 173/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6315 - accuracy: 0.6477 - val_loss: 0.6305 - val_accuracy: 0.6504\n",
            "Epoch 174/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6313 - accuracy: 0.6477 - val_loss: 0.6303 - val_accuracy: 0.6504\n",
            "Epoch 175/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6312 - accuracy: 0.6477 - val_loss: 0.6302 - val_accuracy: 0.6504\n",
            "Epoch 176/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6310 - accuracy: 0.6477 - val_loss: 0.6300 - val_accuracy: 0.6504\n",
            "Epoch 177/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6309 - accuracy: 0.6477 - val_loss: 0.6299 - val_accuracy: 0.6504\n",
            "Epoch 178/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6306 - accuracy: 0.6477 - val_loss: 0.6297 - val_accuracy: 0.6504\n",
            "Epoch 179/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6305 - accuracy: 0.6477 - val_loss: 0.6296 - val_accuracy: 0.6504\n",
            "Epoch 180/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6303 - accuracy: 0.6477 - val_loss: 0.6294 - val_accuracy: 0.6504\n",
            "Epoch 181/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6301 - accuracy: 0.6477 - val_loss: 0.6292 - val_accuracy: 0.6504\n",
            "Epoch 182/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6299 - accuracy: 0.6477 - val_loss: 0.6291 - val_accuracy: 0.6504\n",
            "Epoch 183/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6297 - accuracy: 0.6477 - val_loss: 0.6289 - val_accuracy: 0.6504\n",
            "Epoch 184/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6296 - accuracy: 0.6477 - val_loss: 0.6288 - val_accuracy: 0.6504\n",
            "Epoch 185/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6294 - accuracy: 0.6477 - val_loss: 0.6286 - val_accuracy: 0.6504\n",
            "Epoch 186/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6293 - accuracy: 0.6477 - val_loss: 0.6285 - val_accuracy: 0.6504\n",
            "Epoch 187/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6290 - accuracy: 0.6477 - val_loss: 0.6283 - val_accuracy: 0.6504\n",
            "Epoch 188/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6288 - accuracy: 0.6477 - val_loss: 0.6281 - val_accuracy: 0.6504\n",
            "Epoch 189/1000\n",
            "491/491 [==============================] - 0s 54us/step - loss: 0.6287 - accuracy: 0.6477 - val_loss: 0.6280 - val_accuracy: 0.6504\n",
            "Epoch 190/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.6284 - accuracy: 0.6477 - val_loss: 0.6278 - val_accuracy: 0.6504\n",
            "Epoch 191/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6283 - accuracy: 0.6477 - val_loss: 0.6276 - val_accuracy: 0.6504\n",
            "Epoch 192/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6281 - accuracy: 0.6477 - val_loss: 0.6275 - val_accuracy: 0.6504\n",
            "Epoch 193/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6279 - accuracy: 0.6477 - val_loss: 0.6273 - val_accuracy: 0.6504\n",
            "Epoch 194/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6277 - accuracy: 0.6477 - val_loss: 0.6271 - val_accuracy: 0.6504\n",
            "Epoch 195/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6275 - accuracy: 0.6477 - val_loss: 0.6269 - val_accuracy: 0.6504\n",
            "Epoch 196/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6274 - accuracy: 0.6477 - val_loss: 0.6267 - val_accuracy: 0.6504\n",
            "Epoch 197/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6272 - accuracy: 0.6477 - val_loss: 0.6266 - val_accuracy: 0.6504\n",
            "Epoch 198/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6269 - accuracy: 0.6477 - val_loss: 0.6264 - val_accuracy: 0.6504\n",
            "Epoch 199/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6268 - accuracy: 0.6477 - val_loss: 0.6262 - val_accuracy: 0.6504\n",
            "Epoch 200/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6265 - accuracy: 0.6477 - val_loss: 0.6260 - val_accuracy: 0.6504\n",
            "Epoch 201/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6264 - accuracy: 0.6477 - val_loss: 0.6258 - val_accuracy: 0.6504\n",
            "Epoch 202/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6262 - accuracy: 0.6477 - val_loss: 0.6257 - val_accuracy: 0.6504\n",
            "Epoch 203/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6259 - accuracy: 0.6477 - val_loss: 0.6255 - val_accuracy: 0.6504\n",
            "Epoch 204/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6257 - accuracy: 0.6477 - val_loss: 0.6253 - val_accuracy: 0.6504\n",
            "Epoch 205/1000\n",
            "491/491 [==============================] - 0s 45us/step - loss: 0.6255 - accuracy: 0.6477 - val_loss: 0.6251 - val_accuracy: 0.6504\n",
            "Epoch 206/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6253 - accuracy: 0.6477 - val_loss: 0.6249 - val_accuracy: 0.6504\n",
            "Epoch 207/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6251 - accuracy: 0.6477 - val_loss: 0.6247 - val_accuracy: 0.6504\n",
            "Epoch 208/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6249 - accuracy: 0.6477 - val_loss: 0.6245 - val_accuracy: 0.6504\n",
            "Epoch 209/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6247 - accuracy: 0.6477 - val_loss: 0.6243 - val_accuracy: 0.6504\n",
            "Epoch 210/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.6244 - accuracy: 0.6477 - val_loss: 0.6241 - val_accuracy: 0.6504\n",
            "Epoch 211/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.6242 - accuracy: 0.6477 - val_loss: 0.6239 - val_accuracy: 0.6504\n",
            "Epoch 212/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.6239 - accuracy: 0.6477 - val_loss: 0.6237 - val_accuracy: 0.6504\n",
            "Epoch 213/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6237 - accuracy: 0.6477 - val_loss: 0.6235 - val_accuracy: 0.6504\n",
            "Epoch 214/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6235 - accuracy: 0.6477 - val_loss: 0.6233 - val_accuracy: 0.6504\n",
            "Epoch 215/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6233 - accuracy: 0.6477 - val_loss: 0.6231 - val_accuracy: 0.6504\n",
            "Epoch 216/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6231 - accuracy: 0.6477 - val_loss: 0.6229 - val_accuracy: 0.6585\n",
            "Epoch 217/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6228 - accuracy: 0.6477 - val_loss: 0.6227 - val_accuracy: 0.6585\n",
            "Epoch 218/1000\n",
            "491/491 [==============================] - 0s 45us/step - loss: 0.6226 - accuracy: 0.6477 - val_loss: 0.6225 - val_accuracy: 0.6585\n",
            "Epoch 219/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6224 - accuracy: 0.6477 - val_loss: 0.6223 - val_accuracy: 0.6585\n",
            "Epoch 220/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6222 - accuracy: 0.6477 - val_loss: 0.6221 - val_accuracy: 0.6585\n",
            "Epoch 221/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6219 - accuracy: 0.6477 - val_loss: 0.6219 - val_accuracy: 0.6585\n",
            "Epoch 222/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6217 - accuracy: 0.6477 - val_loss: 0.6217 - val_accuracy: 0.6585\n",
            "Epoch 223/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.6215 - accuracy: 0.6477 - val_loss: 0.6215 - val_accuracy: 0.6585\n",
            "Epoch 224/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6213 - accuracy: 0.6477 - val_loss: 0.6213 - val_accuracy: 0.6585\n",
            "Epoch 225/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6211 - accuracy: 0.6477 - val_loss: 0.6211 - val_accuracy: 0.6585\n",
            "Epoch 226/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6208 - accuracy: 0.6477 - val_loss: 0.6209 - val_accuracy: 0.6585\n",
            "Epoch 227/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6206 - accuracy: 0.6477 - val_loss: 0.6206 - val_accuracy: 0.6585\n",
            "Epoch 228/1000\n",
            "491/491 [==============================] - 0s 52us/step - loss: 0.6203 - accuracy: 0.6477 - val_loss: 0.6204 - val_accuracy: 0.6585\n",
            "Epoch 229/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6200 - accuracy: 0.6477 - val_loss: 0.6202 - val_accuracy: 0.6585\n",
            "Epoch 230/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6198 - accuracy: 0.6477 - val_loss: 0.6200 - val_accuracy: 0.6585\n",
            "Epoch 231/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6196 - accuracy: 0.6477 - val_loss: 0.6198 - val_accuracy: 0.6585\n",
            "Epoch 232/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6193 - accuracy: 0.6477 - val_loss: 0.6196 - val_accuracy: 0.6585\n",
            "Epoch 233/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6191 - accuracy: 0.6477 - val_loss: 0.6193 - val_accuracy: 0.6585\n",
            "Epoch 234/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6189 - accuracy: 0.6477 - val_loss: 0.6191 - val_accuracy: 0.6585\n",
            "Epoch 235/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6185 - accuracy: 0.6477 - val_loss: 0.6189 - val_accuracy: 0.6585\n",
            "Epoch 236/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6182 - accuracy: 0.6477 - val_loss: 0.6187 - val_accuracy: 0.6585\n",
            "Epoch 237/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6181 - accuracy: 0.6477 - val_loss: 0.6184 - val_accuracy: 0.6585\n",
            "Epoch 238/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6178 - accuracy: 0.6477 - val_loss: 0.6182 - val_accuracy: 0.6585\n",
            "Epoch 239/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6176 - accuracy: 0.6477 - val_loss: 0.6180 - val_accuracy: 0.6585\n",
            "Epoch 240/1000\n",
            "491/491 [==============================] - 0s 46us/step - loss: 0.6173 - accuracy: 0.6477 - val_loss: 0.6178 - val_accuracy: 0.6585\n",
            "Epoch 241/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6170 - accuracy: 0.6477 - val_loss: 0.6175 - val_accuracy: 0.6585\n",
            "Epoch 242/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.6168 - accuracy: 0.6477 - val_loss: 0.6173 - val_accuracy: 0.6585\n",
            "Epoch 243/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6164 - accuracy: 0.6477 - val_loss: 0.6170 - val_accuracy: 0.6585\n",
            "Epoch 244/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6161 - accuracy: 0.6477 - val_loss: 0.6168 - val_accuracy: 0.6585\n",
            "Epoch 245/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6159 - accuracy: 0.6477 - val_loss: 0.6166 - val_accuracy: 0.6585\n",
            "Epoch 246/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6158 - accuracy: 0.6477 - val_loss: 0.6163 - val_accuracy: 0.6585\n",
            "Epoch 247/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6153 - accuracy: 0.6477 - val_loss: 0.6161 - val_accuracy: 0.6585\n",
            "Epoch 248/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.6152 - accuracy: 0.6477 - val_loss: 0.6158 - val_accuracy: 0.6585\n",
            "Epoch 249/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6148 - accuracy: 0.6477 - val_loss: 0.6156 - val_accuracy: 0.6585\n",
            "Epoch 250/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6145 - accuracy: 0.6477 - val_loss: 0.6153 - val_accuracy: 0.6585\n",
            "Epoch 251/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6142 - accuracy: 0.6477 - val_loss: 0.6151 - val_accuracy: 0.6585\n",
            "Epoch 252/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6139 - accuracy: 0.6477 - val_loss: 0.6148 - val_accuracy: 0.6585\n",
            "Epoch 253/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6137 - accuracy: 0.6477 - val_loss: 0.6146 - val_accuracy: 0.6585\n",
            "Epoch 254/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6133 - accuracy: 0.6477 - val_loss: 0.6143 - val_accuracy: 0.6585\n",
            "Epoch 255/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6130 - accuracy: 0.6477 - val_loss: 0.6141 - val_accuracy: 0.6585\n",
            "Epoch 256/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6127 - accuracy: 0.6477 - val_loss: 0.6138 - val_accuracy: 0.6585\n",
            "Epoch 257/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6125 - accuracy: 0.6497 - val_loss: 0.6136 - val_accuracy: 0.6504\n",
            "Epoch 258/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.6123 - accuracy: 0.6477 - val_loss: 0.6133 - val_accuracy: 0.6504\n",
            "Epoch 259/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6119 - accuracy: 0.6497 - val_loss: 0.6131 - val_accuracy: 0.6504\n",
            "Epoch 260/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6116 - accuracy: 0.6497 - val_loss: 0.6128 - val_accuracy: 0.6504\n",
            "Epoch 261/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6113 - accuracy: 0.6497 - val_loss: 0.6126 - val_accuracy: 0.6504\n",
            "Epoch 262/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6109 - accuracy: 0.6497 - val_loss: 0.6123 - val_accuracy: 0.6504\n",
            "Epoch 263/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6107 - accuracy: 0.6497 - val_loss: 0.6121 - val_accuracy: 0.6504\n",
            "Epoch 264/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6104 - accuracy: 0.6517 - val_loss: 0.6118 - val_accuracy: 0.6504\n",
            "Epoch 265/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6101 - accuracy: 0.6517 - val_loss: 0.6115 - val_accuracy: 0.6504\n",
            "Epoch 266/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6097 - accuracy: 0.6517 - val_loss: 0.6113 - val_accuracy: 0.6504\n",
            "Epoch 267/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6094 - accuracy: 0.6517 - val_loss: 0.6110 - val_accuracy: 0.6504\n",
            "Epoch 268/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6091 - accuracy: 0.6517 - val_loss: 0.6107 - val_accuracy: 0.6504\n",
            "Epoch 269/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6088 - accuracy: 0.6517 - val_loss: 0.6104 - val_accuracy: 0.6504\n",
            "Epoch 270/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6085 - accuracy: 0.6517 - val_loss: 0.6102 - val_accuracy: 0.6504\n",
            "Epoch 271/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6081 - accuracy: 0.6558 - val_loss: 0.6099 - val_accuracy: 0.6504\n",
            "Epoch 272/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6079 - accuracy: 0.6558 - val_loss: 0.6096 - val_accuracy: 0.6504\n",
            "Epoch 273/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6075 - accuracy: 0.6558 - val_loss: 0.6093 - val_accuracy: 0.6504\n",
            "Epoch 274/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6071 - accuracy: 0.6558 - val_loss: 0.6091 - val_accuracy: 0.6504\n",
            "Epoch 275/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6069 - accuracy: 0.6558 - val_loss: 0.6088 - val_accuracy: 0.6504\n",
            "Epoch 276/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6066 - accuracy: 0.6558 - val_loss: 0.6085 - val_accuracy: 0.6504\n",
            "Epoch 277/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.6061 - accuracy: 0.6619 - val_loss: 0.6082 - val_accuracy: 0.6504\n",
            "Epoch 278/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6059 - accuracy: 0.6599 - val_loss: 0.6079 - val_accuracy: 0.6504\n",
            "Epoch 279/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6055 - accuracy: 0.6619 - val_loss: 0.6076 - val_accuracy: 0.6504\n",
            "Epoch 280/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.6051 - accuracy: 0.6619 - val_loss: 0.6073 - val_accuracy: 0.6504\n",
            "Epoch 281/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6048 - accuracy: 0.6619 - val_loss: 0.6070 - val_accuracy: 0.6504\n",
            "Epoch 282/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6044 - accuracy: 0.6619 - val_loss: 0.6067 - val_accuracy: 0.6504\n",
            "Epoch 283/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6041 - accuracy: 0.6599 - val_loss: 0.6064 - val_accuracy: 0.6504\n",
            "Epoch 284/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6038 - accuracy: 0.6599 - val_loss: 0.6061 - val_accuracy: 0.6504\n",
            "Epoch 285/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6035 - accuracy: 0.6619 - val_loss: 0.6058 - val_accuracy: 0.6504\n",
            "Epoch 286/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6030 - accuracy: 0.6578 - val_loss: 0.6055 - val_accuracy: 0.6504\n",
            "Epoch 287/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6027 - accuracy: 0.6578 - val_loss: 0.6053 - val_accuracy: 0.6504\n",
            "Epoch 288/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6024 - accuracy: 0.6619 - val_loss: 0.6050 - val_accuracy: 0.6504\n",
            "Epoch 289/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6021 - accuracy: 0.6619 - val_loss: 0.6047 - val_accuracy: 0.6504\n",
            "Epoch 290/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6016 - accuracy: 0.6660 - val_loss: 0.6043 - val_accuracy: 0.6504\n",
            "Epoch 291/1000\n",
            "491/491 [==============================] - 0s 50us/step - loss: 0.6014 - accuracy: 0.6721 - val_loss: 0.6040 - val_accuracy: 0.6504\n",
            "Epoch 292/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6009 - accuracy: 0.6701 - val_loss: 0.6037 - val_accuracy: 0.6504\n",
            "Epoch 293/1000\n",
            "491/491 [==============================] - 0s 46us/step - loss: 0.6007 - accuracy: 0.6701 - val_loss: 0.6034 - val_accuracy: 0.6504\n",
            "Epoch 294/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6002 - accuracy: 0.6701 - val_loss: 0.6031 - val_accuracy: 0.6504\n",
            "Epoch 295/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5998 - accuracy: 0.6741 - val_loss: 0.6028 - val_accuracy: 0.6504\n",
            "Epoch 296/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5995 - accuracy: 0.6741 - val_loss: 0.6024 - val_accuracy: 0.6504\n",
            "Epoch 297/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5992 - accuracy: 0.6701 - val_loss: 0.6021 - val_accuracy: 0.6504\n",
            "Epoch 298/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5988 - accuracy: 0.6802 - val_loss: 0.6018 - val_accuracy: 0.6504\n",
            "Epoch 299/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5983 - accuracy: 0.6782 - val_loss: 0.6015 - val_accuracy: 0.6504\n",
            "Epoch 300/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5980 - accuracy: 0.6762 - val_loss: 0.6011 - val_accuracy: 0.6423\n",
            "Epoch 301/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5976 - accuracy: 0.6741 - val_loss: 0.6008 - val_accuracy: 0.6423\n",
            "Epoch 302/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5972 - accuracy: 0.6782 - val_loss: 0.6005 - val_accuracy: 0.6423\n",
            "Epoch 303/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5969 - accuracy: 0.6802 - val_loss: 0.6002 - val_accuracy: 0.6423\n",
            "Epoch 304/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5964 - accuracy: 0.6802 - val_loss: 0.5998 - val_accuracy: 0.6423\n",
            "Epoch 305/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5961 - accuracy: 0.6782 - val_loss: 0.5995 - val_accuracy: 0.6423\n",
            "Epoch 306/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5956 - accuracy: 0.6802 - val_loss: 0.5992 - val_accuracy: 0.6423\n",
            "Epoch 307/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5953 - accuracy: 0.6823 - val_loss: 0.5988 - val_accuracy: 0.6504\n",
            "Epoch 308/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.5949 - accuracy: 0.6802 - val_loss: 0.5985 - val_accuracy: 0.6504\n",
            "Epoch 309/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5945 - accuracy: 0.6823 - val_loss: 0.5981 - val_accuracy: 0.6504\n",
            "Epoch 310/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5942 - accuracy: 0.6843 - val_loss: 0.5978 - val_accuracy: 0.6504\n",
            "Epoch 311/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5938 - accuracy: 0.6823 - val_loss: 0.5975 - val_accuracy: 0.6504\n",
            "Epoch 312/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5933 - accuracy: 0.6843 - val_loss: 0.5971 - val_accuracy: 0.6504\n",
            "Epoch 313/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5929 - accuracy: 0.6843 - val_loss: 0.5968 - val_accuracy: 0.6504\n",
            "Epoch 314/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5925 - accuracy: 0.6884 - val_loss: 0.5964 - val_accuracy: 0.6504\n",
            "Epoch 315/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5921 - accuracy: 0.6884 - val_loss: 0.5961 - val_accuracy: 0.6504\n",
            "Epoch 316/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5917 - accuracy: 0.6884 - val_loss: 0.5957 - val_accuracy: 0.6504\n",
            "Epoch 317/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5912 - accuracy: 0.6884 - val_loss: 0.5954 - val_accuracy: 0.6504\n",
            "Epoch 318/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5910 - accuracy: 0.6884 - val_loss: 0.5950 - val_accuracy: 0.6423\n",
            "Epoch 319/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5905 - accuracy: 0.6925 - val_loss: 0.5947 - val_accuracy: 0.6423\n",
            "Epoch 320/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5901 - accuracy: 0.6925 - val_loss: 0.5944 - val_accuracy: 0.6423\n",
            "Epoch 321/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5897 - accuracy: 0.6904 - val_loss: 0.5940 - val_accuracy: 0.6423\n",
            "Epoch 322/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5893 - accuracy: 0.6904 - val_loss: 0.5936 - val_accuracy: 0.6423\n",
            "Epoch 323/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5889 - accuracy: 0.6904 - val_loss: 0.5933 - val_accuracy: 0.6504\n",
            "Epoch 324/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5884 - accuracy: 0.6986 - val_loss: 0.5929 - val_accuracy: 0.6504\n",
            "Epoch 325/1000\n",
            "491/491 [==============================] - 0s 50us/step - loss: 0.5880 - accuracy: 0.6965 - val_loss: 0.5925 - val_accuracy: 0.6423\n",
            "Epoch 326/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5876 - accuracy: 0.6965 - val_loss: 0.5922 - val_accuracy: 0.6423\n",
            "Epoch 327/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.5871 - accuracy: 0.7026 - val_loss: 0.5918 - val_accuracy: 0.6423\n",
            "Epoch 328/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5867 - accuracy: 0.7026 - val_loss: 0.5915 - val_accuracy: 0.6423\n",
            "Epoch 329/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5863 - accuracy: 0.6986 - val_loss: 0.5911 - val_accuracy: 0.6423\n",
            "Epoch 330/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5859 - accuracy: 0.7026 - val_loss: 0.5907 - val_accuracy: 0.6423\n",
            "Epoch 331/1000\n",
            "491/491 [==============================] - 0s 46us/step - loss: 0.5854 - accuracy: 0.7026 - val_loss: 0.5903 - val_accuracy: 0.6423\n",
            "Epoch 332/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5851 - accuracy: 0.7047 - val_loss: 0.5899 - val_accuracy: 0.6423\n",
            "Epoch 333/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5846 - accuracy: 0.7006 - val_loss: 0.5895 - val_accuracy: 0.6423\n",
            "Epoch 334/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.5843 - accuracy: 0.7026 - val_loss: 0.5892 - val_accuracy: 0.6423\n",
            "Epoch 335/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5837 - accuracy: 0.6986 - val_loss: 0.5888 - val_accuracy: 0.6423\n",
            "Epoch 336/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.5832 - accuracy: 0.6986 - val_loss: 0.5884 - val_accuracy: 0.6423\n",
            "Epoch 337/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5832 - accuracy: 0.6986 - val_loss: 0.5880 - val_accuracy: 0.6423\n",
            "Epoch 338/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5824 - accuracy: 0.7006 - val_loss: 0.5876 - val_accuracy: 0.6423\n",
            "Epoch 339/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5819 - accuracy: 0.6986 - val_loss: 0.5872 - val_accuracy: 0.6341\n",
            "Epoch 340/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5815 - accuracy: 0.6986 - val_loss: 0.5868 - val_accuracy: 0.6341\n",
            "Epoch 341/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5810 - accuracy: 0.7026 - val_loss: 0.5864 - val_accuracy: 0.6341\n",
            "Epoch 342/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.5806 - accuracy: 0.6986 - val_loss: 0.5860 - val_accuracy: 0.6341\n",
            "Epoch 343/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5800 - accuracy: 0.7047 - val_loss: 0.5856 - val_accuracy: 0.6341\n",
            "Epoch 344/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5796 - accuracy: 0.7047 - val_loss: 0.5852 - val_accuracy: 0.6341\n",
            "Epoch 345/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.5793 - accuracy: 0.7067 - val_loss: 0.5849 - val_accuracy: 0.6341\n",
            "Epoch 346/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5788 - accuracy: 0.7067 - val_loss: 0.5845 - val_accuracy: 0.6423\n",
            "Epoch 347/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5783 - accuracy: 0.7047 - val_loss: 0.5841 - val_accuracy: 0.6423\n",
            "Epoch 348/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5778 - accuracy: 0.7067 - val_loss: 0.5837 - val_accuracy: 0.6423\n",
            "Epoch 349/1000\n",
            "491/491 [==============================] - 0s 48us/step - loss: 0.5773 - accuracy: 0.7067 - val_loss: 0.5834 - val_accuracy: 0.6504\n",
            "Epoch 350/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.5769 - accuracy: 0.7047 - val_loss: 0.5830 - val_accuracy: 0.6504\n",
            "Epoch 351/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.5764 - accuracy: 0.7067 - val_loss: 0.5826 - val_accuracy: 0.6585\n",
            "Epoch 352/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5759 - accuracy: 0.7026 - val_loss: 0.5822 - val_accuracy: 0.6504\n",
            "Epoch 353/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.5754 - accuracy: 0.7067 - val_loss: 0.5818 - val_accuracy: 0.6504\n",
            "Epoch 354/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5749 - accuracy: 0.7047 - val_loss: 0.5814 - val_accuracy: 0.6585\n",
            "Epoch 355/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5744 - accuracy: 0.7047 - val_loss: 0.5810 - val_accuracy: 0.6585\n",
            "Epoch 356/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5739 - accuracy: 0.7047 - val_loss: 0.5806 - val_accuracy: 0.6748\n",
            "Epoch 357/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5734 - accuracy: 0.7006 - val_loss: 0.5802 - val_accuracy: 0.6667\n",
            "Epoch 358/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5730 - accuracy: 0.7026 - val_loss: 0.5798 - val_accuracy: 0.6748\n",
            "Epoch 359/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.5727 - accuracy: 0.7026 - val_loss: 0.5794 - val_accuracy: 0.6748\n",
            "Epoch 360/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5720 - accuracy: 0.7026 - val_loss: 0.5790 - val_accuracy: 0.6748\n",
            "Epoch 361/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5715 - accuracy: 0.7067 - val_loss: 0.5787 - val_accuracy: 0.6667\n",
            "Epoch 362/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5711 - accuracy: 0.7026 - val_loss: 0.5783 - val_accuracy: 0.6667\n",
            "Epoch 363/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5704 - accuracy: 0.7047 - val_loss: 0.5779 - val_accuracy: 0.6667\n",
            "Epoch 364/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5701 - accuracy: 0.7047 - val_loss: 0.5775 - val_accuracy: 0.6667\n",
            "Epoch 365/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5696 - accuracy: 0.7047 - val_loss: 0.5772 - val_accuracy: 0.6829\n",
            "Epoch 366/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5689 - accuracy: 0.7026 - val_loss: 0.5768 - val_accuracy: 0.6667\n",
            "Epoch 367/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5685 - accuracy: 0.7067 - val_loss: 0.5764 - val_accuracy: 0.6829\n",
            "Epoch 368/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5680 - accuracy: 0.7026 - val_loss: 0.5760 - val_accuracy: 0.6829\n",
            "Epoch 369/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5676 - accuracy: 0.7067 - val_loss: 0.5756 - val_accuracy: 0.6829\n",
            "Epoch 370/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5669 - accuracy: 0.7047 - val_loss: 0.5752 - val_accuracy: 0.6829\n",
            "Epoch 371/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5666 - accuracy: 0.7067 - val_loss: 0.5748 - val_accuracy: 0.6829\n",
            "Epoch 372/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5660 - accuracy: 0.7026 - val_loss: 0.5744 - val_accuracy: 0.6829\n",
            "Epoch 373/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5656 - accuracy: 0.7047 - val_loss: 0.5740 - val_accuracy: 0.6829\n",
            "Epoch 374/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5653 - accuracy: 0.7047 - val_loss: 0.5737 - val_accuracy: 0.6829\n",
            "Epoch 375/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5645 - accuracy: 0.7047 - val_loss: 0.5733 - val_accuracy: 0.6829\n",
            "Epoch 376/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5638 - accuracy: 0.7047 - val_loss: 0.5729 - val_accuracy: 0.6829\n",
            "Epoch 377/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5634 - accuracy: 0.7047 - val_loss: 0.5725 - val_accuracy: 0.6829\n",
            "Epoch 378/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5630 - accuracy: 0.7067 - val_loss: 0.5722 - val_accuracy: 0.6829\n",
            "Epoch 379/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5624 - accuracy: 0.7067 - val_loss: 0.5718 - val_accuracy: 0.6829\n",
            "Epoch 380/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5620 - accuracy: 0.7088 - val_loss: 0.5714 - val_accuracy: 0.6829\n",
            "Epoch 381/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5614 - accuracy: 0.7067 - val_loss: 0.5710 - val_accuracy: 0.6829\n",
            "Epoch 382/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5610 - accuracy: 0.7026 - val_loss: 0.5706 - val_accuracy: 0.6829\n",
            "Epoch 383/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5604 - accuracy: 0.7067 - val_loss: 0.5702 - val_accuracy: 0.6829\n",
            "Epoch 384/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5600 - accuracy: 0.7067 - val_loss: 0.5699 - val_accuracy: 0.6829\n",
            "Epoch 385/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5593 - accuracy: 0.7047 - val_loss: 0.5694 - val_accuracy: 0.6829\n",
            "Epoch 386/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5588 - accuracy: 0.7067 - val_loss: 0.5690 - val_accuracy: 0.6829\n",
            "Epoch 387/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5584 - accuracy: 0.7088 - val_loss: 0.5686 - val_accuracy: 0.6829\n",
            "Epoch 388/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5579 - accuracy: 0.7067 - val_loss: 0.5682 - val_accuracy: 0.6829\n",
            "Epoch 389/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5576 - accuracy: 0.7047 - val_loss: 0.5678 - val_accuracy: 0.6829\n",
            "Epoch 390/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5572 - accuracy: 0.7067 - val_loss: 0.5675 - val_accuracy: 0.6911\n",
            "Epoch 391/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5564 - accuracy: 0.7088 - val_loss: 0.5671 - val_accuracy: 0.6911\n",
            "Epoch 392/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.5558 - accuracy: 0.7088 - val_loss: 0.5667 - val_accuracy: 0.6911\n",
            "Epoch 393/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5555 - accuracy: 0.7088 - val_loss: 0.5663 - val_accuracy: 0.6911\n",
            "Epoch 394/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5548 - accuracy: 0.7088 - val_loss: 0.5659 - val_accuracy: 0.6911\n",
            "Epoch 395/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.5544 - accuracy: 0.7067 - val_loss: 0.5655 - val_accuracy: 0.6911\n",
            "Epoch 396/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5541 - accuracy: 0.7067 - val_loss: 0.5651 - val_accuracy: 0.6911\n",
            "Epoch 397/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5535 - accuracy: 0.7067 - val_loss: 0.5648 - val_accuracy: 0.6911\n",
            "Epoch 398/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5528 - accuracy: 0.7067 - val_loss: 0.5644 - val_accuracy: 0.6911\n",
            "Epoch 399/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5525 - accuracy: 0.7067 - val_loss: 0.5641 - val_accuracy: 0.6911\n",
            "Epoch 400/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5523 - accuracy: 0.7088 - val_loss: 0.5638 - val_accuracy: 0.6911\n",
            "Epoch 401/1000\n",
            "491/491 [==============================] - 0s 51us/step - loss: 0.5515 - accuracy: 0.7088 - val_loss: 0.5633 - val_accuracy: 0.6911\n",
            "Epoch 402/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5510 - accuracy: 0.7067 - val_loss: 0.5630 - val_accuracy: 0.6911\n",
            "Epoch 403/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5503 - accuracy: 0.7067 - val_loss: 0.5626 - val_accuracy: 0.6911\n",
            "Epoch 404/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5500 - accuracy: 0.7088 - val_loss: 0.5622 - val_accuracy: 0.6911\n",
            "Epoch 405/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5496 - accuracy: 0.7047 - val_loss: 0.5619 - val_accuracy: 0.6911\n",
            "Epoch 406/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5491 - accuracy: 0.7067 - val_loss: 0.5615 - val_accuracy: 0.6911\n",
            "Epoch 407/1000\n",
            "491/491 [==============================] - 0s 46us/step - loss: 0.5489 - accuracy: 0.7108 - val_loss: 0.5611 - val_accuracy: 0.6911\n",
            "Epoch 408/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5480 - accuracy: 0.7067 - val_loss: 0.5606 - val_accuracy: 0.6911\n",
            "Epoch 409/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5475 - accuracy: 0.7067 - val_loss: 0.5602 - val_accuracy: 0.6911\n",
            "Epoch 410/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5469 - accuracy: 0.7088 - val_loss: 0.5599 - val_accuracy: 0.6911\n",
            "Epoch 411/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.5466 - accuracy: 0.7088 - val_loss: 0.5595 - val_accuracy: 0.6911\n",
            "Epoch 412/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5461 - accuracy: 0.7067 - val_loss: 0.5590 - val_accuracy: 0.6911\n",
            "Epoch 413/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5458 - accuracy: 0.7088 - val_loss: 0.5586 - val_accuracy: 0.6911\n",
            "Epoch 414/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5452 - accuracy: 0.7088 - val_loss: 0.5584 - val_accuracy: 0.6911\n",
            "Epoch 415/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5448 - accuracy: 0.7088 - val_loss: 0.5579 - val_accuracy: 0.6911\n",
            "Epoch 416/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5445 - accuracy: 0.7067 - val_loss: 0.5575 - val_accuracy: 0.6911\n",
            "Epoch 417/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5437 - accuracy: 0.7128 - val_loss: 0.5571 - val_accuracy: 0.6911\n",
            "Epoch 418/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.5432 - accuracy: 0.7108 - val_loss: 0.5567 - val_accuracy: 0.6911\n",
            "Epoch 419/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5427 - accuracy: 0.7088 - val_loss: 0.5564 - val_accuracy: 0.6911\n",
            "Epoch 420/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5424 - accuracy: 0.7088 - val_loss: 0.5560 - val_accuracy: 0.6911\n",
            "Epoch 421/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.5417 - accuracy: 0.7108 - val_loss: 0.5558 - val_accuracy: 0.6911\n",
            "Epoch 422/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5414 - accuracy: 0.7088 - val_loss: 0.5555 - val_accuracy: 0.6911\n",
            "Epoch 423/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5408 - accuracy: 0.7108 - val_loss: 0.5551 - val_accuracy: 0.6911\n",
            "Epoch 424/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5404 - accuracy: 0.7128 - val_loss: 0.5548 - val_accuracy: 0.6992\n",
            "Epoch 425/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5398 - accuracy: 0.7128 - val_loss: 0.5543 - val_accuracy: 0.6911\n",
            "Epoch 426/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5394 - accuracy: 0.7128 - val_loss: 0.5539 - val_accuracy: 0.6992\n",
            "Epoch 427/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5389 - accuracy: 0.7128 - val_loss: 0.5536 - val_accuracy: 0.6992\n",
            "Epoch 428/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5387 - accuracy: 0.7128 - val_loss: 0.5533 - val_accuracy: 0.6992\n",
            "Epoch 429/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5380 - accuracy: 0.7108 - val_loss: 0.5530 - val_accuracy: 0.6992\n",
            "Epoch 430/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5374 - accuracy: 0.7128 - val_loss: 0.5527 - val_accuracy: 0.7073\n",
            "Epoch 431/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5369 - accuracy: 0.7108 - val_loss: 0.5523 - val_accuracy: 0.7073\n",
            "Epoch 432/1000\n",
            "491/491 [==============================] - 0s 46us/step - loss: 0.5366 - accuracy: 0.7149 - val_loss: 0.5519 - val_accuracy: 0.7073\n",
            "Epoch 433/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5362 - accuracy: 0.7128 - val_loss: 0.5516 - val_accuracy: 0.7154\n",
            "Epoch 434/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5357 - accuracy: 0.7128 - val_loss: 0.5510 - val_accuracy: 0.7073\n",
            "Epoch 435/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5353 - accuracy: 0.7149 - val_loss: 0.5506 - val_accuracy: 0.7073\n",
            "Epoch 436/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5346 - accuracy: 0.7128 - val_loss: 0.5504 - val_accuracy: 0.7154\n",
            "Epoch 437/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5344 - accuracy: 0.7149 - val_loss: 0.5501 - val_accuracy: 0.7154\n",
            "Epoch 438/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5340 - accuracy: 0.7189 - val_loss: 0.5497 - val_accuracy: 0.7154\n",
            "Epoch 439/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5333 - accuracy: 0.7169 - val_loss: 0.5494 - val_accuracy: 0.7154\n",
            "Epoch 440/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5332 - accuracy: 0.7189 - val_loss: 0.5489 - val_accuracy: 0.7236\n",
            "Epoch 441/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5327 - accuracy: 0.7189 - val_loss: 0.5487 - val_accuracy: 0.7154\n",
            "Epoch 442/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5320 - accuracy: 0.7189 - val_loss: 0.5483 - val_accuracy: 0.7236\n",
            "Epoch 443/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5316 - accuracy: 0.7210 - val_loss: 0.5481 - val_accuracy: 0.7154\n",
            "Epoch 444/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5312 - accuracy: 0.7189 - val_loss: 0.5476 - val_accuracy: 0.7236\n",
            "Epoch 445/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5305 - accuracy: 0.7189 - val_loss: 0.5474 - val_accuracy: 0.7154\n",
            "Epoch 446/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5300 - accuracy: 0.7189 - val_loss: 0.5471 - val_accuracy: 0.7154\n",
            "Epoch 447/1000\n",
            "491/491 [==============================] - 0s 50us/step - loss: 0.5297 - accuracy: 0.7210 - val_loss: 0.5466 - val_accuracy: 0.7154\n",
            "Epoch 448/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5293 - accuracy: 0.7189 - val_loss: 0.5464 - val_accuracy: 0.7154\n",
            "Epoch 449/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.5287 - accuracy: 0.7189 - val_loss: 0.5461 - val_accuracy: 0.7154\n",
            "Epoch 450/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5284 - accuracy: 0.7128 - val_loss: 0.5457 - val_accuracy: 0.7154\n",
            "Epoch 451/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5280 - accuracy: 0.7230 - val_loss: 0.5455 - val_accuracy: 0.7073\n",
            "Epoch 452/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5274 - accuracy: 0.7210 - val_loss: 0.5453 - val_accuracy: 0.7073\n",
            "Epoch 453/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5269 - accuracy: 0.7169 - val_loss: 0.5450 - val_accuracy: 0.7073\n",
            "Epoch 454/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5264 - accuracy: 0.7128 - val_loss: 0.5446 - val_accuracy: 0.7073\n",
            "Epoch 455/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5261 - accuracy: 0.7169 - val_loss: 0.5442 - val_accuracy: 0.7073\n",
            "Epoch 456/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.5256 - accuracy: 0.7149 - val_loss: 0.5438 - val_accuracy: 0.7073\n",
            "Epoch 457/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5252 - accuracy: 0.7189 - val_loss: 0.5436 - val_accuracy: 0.7073\n",
            "Epoch 458/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5246 - accuracy: 0.7128 - val_loss: 0.5432 - val_accuracy: 0.7073\n",
            "Epoch 459/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5243 - accuracy: 0.7189 - val_loss: 0.5427 - val_accuracy: 0.7073\n",
            "Epoch 460/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5238 - accuracy: 0.7189 - val_loss: 0.5425 - val_accuracy: 0.7073\n",
            "Epoch 461/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5236 - accuracy: 0.7169 - val_loss: 0.5422 - val_accuracy: 0.7073\n",
            "Epoch 462/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5232 - accuracy: 0.7169 - val_loss: 0.5419 - val_accuracy: 0.7073\n",
            "Epoch 463/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5225 - accuracy: 0.7210 - val_loss: 0.5416 - val_accuracy: 0.7073\n",
            "Epoch 464/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5226 - accuracy: 0.7189 - val_loss: 0.5414 - val_accuracy: 0.6992\n",
            "Epoch 465/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5216 - accuracy: 0.7210 - val_loss: 0.5411 - val_accuracy: 0.6992\n",
            "Epoch 466/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5212 - accuracy: 0.7210 - val_loss: 0.5407 - val_accuracy: 0.6992\n",
            "Epoch 467/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5210 - accuracy: 0.7230 - val_loss: 0.5402 - val_accuracy: 0.7073\n",
            "Epoch 468/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5207 - accuracy: 0.7230 - val_loss: 0.5399 - val_accuracy: 0.7073\n",
            "Epoch 469/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5203 - accuracy: 0.7230 - val_loss: 0.5396 - val_accuracy: 0.6992\n",
            "Epoch 470/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5196 - accuracy: 0.7271 - val_loss: 0.5393 - val_accuracy: 0.6992\n",
            "Epoch 471/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.5192 - accuracy: 0.7230 - val_loss: 0.5390 - val_accuracy: 0.6992\n",
            "Epoch 472/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5190 - accuracy: 0.7210 - val_loss: 0.5389 - val_accuracy: 0.6992\n",
            "Epoch 473/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5183 - accuracy: 0.7251 - val_loss: 0.5388 - val_accuracy: 0.6992\n",
            "Epoch 474/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5178 - accuracy: 0.7251 - val_loss: 0.5384 - val_accuracy: 0.6992\n",
            "Epoch 475/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5172 - accuracy: 0.7271 - val_loss: 0.5382 - val_accuracy: 0.6992\n",
            "Epoch 476/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5169 - accuracy: 0.7251 - val_loss: 0.5378 - val_accuracy: 0.6992\n",
            "Epoch 477/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5164 - accuracy: 0.7251 - val_loss: 0.5375 - val_accuracy: 0.7073\n",
            "Epoch 478/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5162 - accuracy: 0.7271 - val_loss: 0.5373 - val_accuracy: 0.7073\n",
            "Epoch 479/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5160 - accuracy: 0.7210 - val_loss: 0.5369 - val_accuracy: 0.7073\n",
            "Epoch 480/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.5152 - accuracy: 0.7251 - val_loss: 0.5366 - val_accuracy: 0.7073\n",
            "Epoch 481/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5148 - accuracy: 0.7230 - val_loss: 0.5362 - val_accuracy: 0.7073\n",
            "Epoch 482/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5144 - accuracy: 0.7251 - val_loss: 0.5358 - val_accuracy: 0.7073\n",
            "Epoch 483/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5139 - accuracy: 0.7291 - val_loss: 0.5355 - val_accuracy: 0.7073\n",
            "Epoch 484/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.5140 - accuracy: 0.7332 - val_loss: 0.5355 - val_accuracy: 0.7073\n",
            "Epoch 485/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5131 - accuracy: 0.7291 - val_loss: 0.5354 - val_accuracy: 0.7073\n",
            "Epoch 486/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5126 - accuracy: 0.7251 - val_loss: 0.5349 - val_accuracy: 0.7073\n",
            "Epoch 487/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5124 - accuracy: 0.7312 - val_loss: 0.5344 - val_accuracy: 0.7073\n",
            "Epoch 488/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5121 - accuracy: 0.7251 - val_loss: 0.5343 - val_accuracy: 0.7073\n",
            "Epoch 489/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5117 - accuracy: 0.7312 - val_loss: 0.5339 - val_accuracy: 0.7073\n",
            "Epoch 490/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5110 - accuracy: 0.7332 - val_loss: 0.5338 - val_accuracy: 0.7073\n",
            "Epoch 491/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5107 - accuracy: 0.7291 - val_loss: 0.5338 - val_accuracy: 0.7073\n",
            "Epoch 492/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5103 - accuracy: 0.7271 - val_loss: 0.5335 - val_accuracy: 0.7073\n",
            "Epoch 493/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5100 - accuracy: 0.7291 - val_loss: 0.5333 - val_accuracy: 0.7073\n",
            "Epoch 494/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5099 - accuracy: 0.7271 - val_loss: 0.5330 - val_accuracy: 0.7073\n",
            "Epoch 495/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5093 - accuracy: 0.7271 - val_loss: 0.5325 - val_accuracy: 0.6992\n",
            "Epoch 496/1000\n",
            "491/491 [==============================] - 0s 45us/step - loss: 0.5088 - accuracy: 0.7312 - val_loss: 0.5321 - val_accuracy: 0.6992\n",
            "Epoch 497/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5081 - accuracy: 0.7332 - val_loss: 0.5322 - val_accuracy: 0.7073\n",
            "Epoch 498/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5082 - accuracy: 0.7291 - val_loss: 0.5319 - val_accuracy: 0.7073\n",
            "Epoch 499/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5077 - accuracy: 0.7291 - val_loss: 0.5316 - val_accuracy: 0.6992\n",
            "Epoch 500/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.5070 - accuracy: 0.7312 - val_loss: 0.5309 - val_accuracy: 0.7073\n",
            "Epoch 501/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5066 - accuracy: 0.7291 - val_loss: 0.5308 - val_accuracy: 0.7073\n",
            "Epoch 502/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5062 - accuracy: 0.7291 - val_loss: 0.5305 - val_accuracy: 0.7073\n",
            "Epoch 503/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5063 - accuracy: 0.7312 - val_loss: 0.5300 - val_accuracy: 0.7073\n",
            "Epoch 504/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5054 - accuracy: 0.7393 - val_loss: 0.5302 - val_accuracy: 0.6992\n",
            "Epoch 505/1000\n",
            "491/491 [==============================] - 0s 50us/step - loss: 0.5056 - accuracy: 0.7332 - val_loss: 0.5300 - val_accuracy: 0.6992\n",
            "Epoch 506/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5047 - accuracy: 0.7332 - val_loss: 0.5300 - val_accuracy: 0.6911\n",
            "Epoch 507/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5046 - accuracy: 0.7332 - val_loss: 0.5297 - val_accuracy: 0.6911\n",
            "Epoch 508/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5039 - accuracy: 0.7332 - val_loss: 0.5293 - val_accuracy: 0.6992\n",
            "Epoch 509/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5034 - accuracy: 0.7312 - val_loss: 0.5292 - val_accuracy: 0.6911\n",
            "Epoch 510/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5030 - accuracy: 0.7332 - val_loss: 0.5291 - val_accuracy: 0.6911\n",
            "Epoch 511/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5030 - accuracy: 0.7352 - val_loss: 0.5289 - val_accuracy: 0.6911\n",
            "Epoch 512/1000\n",
            "491/491 [==============================] - 0s 47us/step - loss: 0.5025 - accuracy: 0.7312 - val_loss: 0.5287 - val_accuracy: 0.6911\n",
            "Epoch 513/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5022 - accuracy: 0.7373 - val_loss: 0.5280 - val_accuracy: 0.7073\n",
            "Epoch 514/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5016 - accuracy: 0.7352 - val_loss: 0.5278 - val_accuracy: 0.7073\n",
            "Epoch 515/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5016 - accuracy: 0.7373 - val_loss: 0.5276 - val_accuracy: 0.7073\n",
            "Epoch 516/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5010 - accuracy: 0.7373 - val_loss: 0.5277 - val_accuracy: 0.6911\n",
            "Epoch 517/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5005 - accuracy: 0.7312 - val_loss: 0.5274 - val_accuracy: 0.6911\n",
            "Epoch 518/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5003 - accuracy: 0.7312 - val_loss: 0.5270 - val_accuracy: 0.6992\n",
            "Epoch 519/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5001 - accuracy: 0.7373 - val_loss: 0.5269 - val_accuracy: 0.6992\n",
            "Epoch 520/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4994 - accuracy: 0.7352 - val_loss: 0.5264 - val_accuracy: 0.6992\n",
            "Epoch 521/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4992 - accuracy: 0.7332 - val_loss: 0.5261 - val_accuracy: 0.6992\n",
            "Epoch 522/1000\n",
            "491/491 [==============================] - 0s 47us/step - loss: 0.4989 - accuracy: 0.7373 - val_loss: 0.5257 - val_accuracy: 0.7073\n",
            "Epoch 523/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4986 - accuracy: 0.7373 - val_loss: 0.5258 - val_accuracy: 0.6992\n",
            "Epoch 524/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4983 - accuracy: 0.7352 - val_loss: 0.5253 - val_accuracy: 0.6992\n",
            "Epoch 525/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4975 - accuracy: 0.7413 - val_loss: 0.5254 - val_accuracy: 0.6992\n",
            "Epoch 526/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4975 - accuracy: 0.7393 - val_loss: 0.5254 - val_accuracy: 0.6992\n",
            "Epoch 527/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4971 - accuracy: 0.7373 - val_loss: 0.5253 - val_accuracy: 0.6992\n",
            "Epoch 528/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4965 - accuracy: 0.7393 - val_loss: 0.5252 - val_accuracy: 0.6911\n",
            "Epoch 529/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4963 - accuracy: 0.7515 - val_loss: 0.5248 - val_accuracy: 0.6992\n",
            "Epoch 530/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4964 - accuracy: 0.7495 - val_loss: 0.5244 - val_accuracy: 0.6992\n",
            "Epoch 531/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4958 - accuracy: 0.7434 - val_loss: 0.5245 - val_accuracy: 0.6911\n",
            "Epoch 532/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4952 - accuracy: 0.7495 - val_loss: 0.5240 - val_accuracy: 0.6992\n",
            "Epoch 533/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4948 - accuracy: 0.7454 - val_loss: 0.5242 - val_accuracy: 0.6911\n",
            "Epoch 534/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4948 - accuracy: 0.7495 - val_loss: 0.5238 - val_accuracy: 0.6992\n",
            "Epoch 535/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4943 - accuracy: 0.7454 - val_loss: 0.5234 - val_accuracy: 0.6992\n",
            "Epoch 536/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4941 - accuracy: 0.7515 - val_loss: 0.5235 - val_accuracy: 0.6911\n",
            "Epoch 537/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4938 - accuracy: 0.7475 - val_loss: 0.5230 - val_accuracy: 0.6992\n",
            "Epoch 538/1000\n",
            "491/491 [==============================] - 0s 46us/step - loss: 0.4932 - accuracy: 0.7536 - val_loss: 0.5226 - val_accuracy: 0.6992\n",
            "Epoch 539/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4934 - accuracy: 0.7434 - val_loss: 0.5227 - val_accuracy: 0.6992\n",
            "Epoch 540/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4926 - accuracy: 0.7536 - val_loss: 0.5224 - val_accuracy: 0.6992\n",
            "Epoch 541/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4921 - accuracy: 0.7556 - val_loss: 0.5222 - val_accuracy: 0.6992\n",
            "Epoch 542/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4917 - accuracy: 0.7515 - val_loss: 0.5218 - val_accuracy: 0.6992\n",
            "Epoch 543/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4915 - accuracy: 0.7515 - val_loss: 0.5217 - val_accuracy: 0.6992\n",
            "Epoch 544/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4911 - accuracy: 0.7556 - val_loss: 0.5215 - val_accuracy: 0.6992\n",
            "Epoch 545/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4909 - accuracy: 0.7536 - val_loss: 0.5215 - val_accuracy: 0.6992\n",
            "Epoch 546/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4907 - accuracy: 0.7536 - val_loss: 0.5213 - val_accuracy: 0.6992\n",
            "Epoch 547/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4904 - accuracy: 0.7536 - val_loss: 0.5211 - val_accuracy: 0.6992\n",
            "Epoch 548/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4904 - accuracy: 0.7556 - val_loss: 0.5206 - val_accuracy: 0.6992\n",
            "Epoch 549/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4901 - accuracy: 0.7576 - val_loss: 0.5208 - val_accuracy: 0.6992\n",
            "Epoch 550/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4894 - accuracy: 0.7556 - val_loss: 0.5206 - val_accuracy: 0.6992\n",
            "Epoch 551/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4888 - accuracy: 0.7515 - val_loss: 0.5203 - val_accuracy: 0.6992\n",
            "Epoch 552/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4887 - accuracy: 0.7515 - val_loss: 0.5201 - val_accuracy: 0.6992\n",
            "Epoch 553/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4887 - accuracy: 0.7556 - val_loss: 0.5197 - val_accuracy: 0.6992\n",
            "Epoch 554/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4884 - accuracy: 0.7617 - val_loss: 0.5200 - val_accuracy: 0.6992\n",
            "Epoch 555/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4884 - accuracy: 0.7536 - val_loss: 0.5196 - val_accuracy: 0.6992\n",
            "Epoch 556/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4873 - accuracy: 0.7515 - val_loss: 0.5195 - val_accuracy: 0.6992\n",
            "Epoch 557/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4872 - accuracy: 0.7556 - val_loss: 0.5192 - val_accuracy: 0.6992\n",
            "Epoch 558/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4873 - accuracy: 0.7536 - val_loss: 0.5191 - val_accuracy: 0.6992\n",
            "Epoch 559/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4866 - accuracy: 0.7556 - val_loss: 0.5191 - val_accuracy: 0.6992\n",
            "Epoch 560/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4862 - accuracy: 0.7515 - val_loss: 0.5192 - val_accuracy: 0.6911\n",
            "Epoch 561/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4861 - accuracy: 0.7536 - val_loss: 0.5187 - val_accuracy: 0.6992\n",
            "Epoch 562/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4860 - accuracy: 0.7515 - val_loss: 0.5187 - val_accuracy: 0.6911\n",
            "Epoch 563/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4859 - accuracy: 0.7556 - val_loss: 0.5188 - val_accuracy: 0.6911\n",
            "Epoch 564/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4856 - accuracy: 0.7556 - val_loss: 0.5189 - val_accuracy: 0.7073\n",
            "Epoch 565/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4850 - accuracy: 0.7556 - val_loss: 0.5181 - val_accuracy: 0.6911\n",
            "Epoch 566/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4848 - accuracy: 0.7515 - val_loss: 0.5178 - val_accuracy: 0.6992\n",
            "Epoch 567/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4855 - accuracy: 0.7617 - val_loss: 0.5178 - val_accuracy: 0.6911\n",
            "Epoch 568/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4841 - accuracy: 0.7536 - val_loss: 0.5178 - val_accuracy: 0.6992\n",
            "Epoch 569/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4840 - accuracy: 0.7576 - val_loss: 0.5177 - val_accuracy: 0.6992\n",
            "Epoch 570/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4836 - accuracy: 0.7536 - val_loss: 0.5176 - val_accuracy: 0.6992\n",
            "Epoch 571/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4832 - accuracy: 0.7576 - val_loss: 0.5175 - val_accuracy: 0.6992\n",
            "Epoch 572/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4832 - accuracy: 0.7536 - val_loss: 0.5171 - val_accuracy: 0.6992\n",
            "Epoch 573/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4825 - accuracy: 0.7536 - val_loss: 0.5172 - val_accuracy: 0.7154\n",
            "Epoch 574/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4823 - accuracy: 0.7617 - val_loss: 0.5163 - val_accuracy: 0.6992\n",
            "Epoch 575/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4821 - accuracy: 0.7658 - val_loss: 0.5164 - val_accuracy: 0.6992\n",
            "Epoch 576/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4815 - accuracy: 0.7536 - val_loss: 0.5162 - val_accuracy: 0.7073\n",
            "Epoch 577/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4821 - accuracy: 0.7576 - val_loss: 0.5162 - val_accuracy: 0.6992\n",
            "Epoch 578/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4813 - accuracy: 0.7536 - val_loss: 0.5162 - val_accuracy: 0.7154\n",
            "Epoch 579/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4807 - accuracy: 0.7556 - val_loss: 0.5158 - val_accuracy: 0.6992\n",
            "Epoch 580/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4808 - accuracy: 0.7556 - val_loss: 0.5156 - val_accuracy: 0.7073\n",
            "Epoch 581/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4806 - accuracy: 0.7597 - val_loss: 0.5158 - val_accuracy: 0.7154\n",
            "Epoch 582/1000\n",
            "491/491 [==============================] - 0s 54us/step - loss: 0.4800 - accuracy: 0.7536 - val_loss: 0.5154 - val_accuracy: 0.7073\n",
            "Epoch 583/1000\n",
            "491/491 [==============================] - 0s 46us/step - loss: 0.4798 - accuracy: 0.7556 - val_loss: 0.5153 - val_accuracy: 0.7073\n",
            "Epoch 584/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4799 - accuracy: 0.7576 - val_loss: 0.5153 - val_accuracy: 0.7154\n",
            "Epoch 585/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4793 - accuracy: 0.7576 - val_loss: 0.5154 - val_accuracy: 0.7154\n",
            "Epoch 586/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4792 - accuracy: 0.7597 - val_loss: 0.5151 - val_accuracy: 0.7154\n",
            "Epoch 587/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4786 - accuracy: 0.7556 - val_loss: 0.5151 - val_accuracy: 0.7154\n",
            "Epoch 588/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4787 - accuracy: 0.7536 - val_loss: 0.5149 - val_accuracy: 0.7154\n",
            "Epoch 589/1000\n",
            "491/491 [==============================] - 0s 44us/step - loss: 0.4787 - accuracy: 0.7576 - val_loss: 0.5152 - val_accuracy: 0.7236\n",
            "Epoch 590/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4779 - accuracy: 0.7637 - val_loss: 0.5143 - val_accuracy: 0.7154\n",
            "Epoch 591/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4779 - accuracy: 0.7597 - val_loss: 0.5144 - val_accuracy: 0.7154\n",
            "Epoch 592/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4784 - accuracy: 0.7556 - val_loss: 0.5144 - val_accuracy: 0.7154\n",
            "Epoch 593/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4774 - accuracy: 0.7617 - val_loss: 0.5140 - val_accuracy: 0.7154\n",
            "Epoch 594/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4771 - accuracy: 0.7637 - val_loss: 0.5141 - val_accuracy: 0.7154\n",
            "Epoch 595/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4770 - accuracy: 0.7617 - val_loss: 0.5139 - val_accuracy: 0.7154\n",
            "Epoch 596/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4769 - accuracy: 0.7597 - val_loss: 0.5138 - val_accuracy: 0.7154\n",
            "Epoch 597/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4764 - accuracy: 0.7576 - val_loss: 0.5137 - val_accuracy: 0.7154\n",
            "Epoch 598/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4765 - accuracy: 0.7637 - val_loss: 0.5134 - val_accuracy: 0.7154\n",
            "Epoch 599/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4759 - accuracy: 0.7637 - val_loss: 0.5131 - val_accuracy: 0.7154\n",
            "Epoch 600/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4760 - accuracy: 0.7576 - val_loss: 0.5132 - val_accuracy: 0.7154\n",
            "Epoch 601/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4758 - accuracy: 0.7637 - val_loss: 0.5134 - val_accuracy: 0.7154\n",
            "Epoch 602/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4758 - accuracy: 0.7637 - val_loss: 0.5130 - val_accuracy: 0.7154\n",
            "Epoch 603/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4748 - accuracy: 0.7658 - val_loss: 0.5134 - val_accuracy: 0.7236\n",
            "Epoch 604/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4747 - accuracy: 0.7637 - val_loss: 0.5129 - val_accuracy: 0.7154\n",
            "Epoch 605/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4746 - accuracy: 0.7699 - val_loss: 0.5126 - val_accuracy: 0.7154\n",
            "Epoch 606/1000\n",
            "491/491 [==============================] - 0s 47us/step - loss: 0.4741 - accuracy: 0.7699 - val_loss: 0.5123 - val_accuracy: 0.7154\n",
            "Epoch 607/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4742 - accuracy: 0.7637 - val_loss: 0.5125 - val_accuracy: 0.7154\n",
            "Epoch 608/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4739 - accuracy: 0.7658 - val_loss: 0.5122 - val_accuracy: 0.7154\n",
            "Epoch 609/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4743 - accuracy: 0.7658 - val_loss: 0.5123 - val_accuracy: 0.7154\n",
            "Epoch 610/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4733 - accuracy: 0.7658 - val_loss: 0.5123 - val_accuracy: 0.7154\n",
            "Epoch 611/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4733 - accuracy: 0.7678 - val_loss: 0.5123 - val_accuracy: 0.7154\n",
            "Epoch 612/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4737 - accuracy: 0.7617 - val_loss: 0.5121 - val_accuracy: 0.7154\n",
            "Epoch 613/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4728 - accuracy: 0.7658 - val_loss: 0.5117 - val_accuracy: 0.7154\n",
            "Epoch 614/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4726 - accuracy: 0.7678 - val_loss: 0.5119 - val_accuracy: 0.7236\n",
            "Epoch 615/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4730 - accuracy: 0.7719 - val_loss: 0.5118 - val_accuracy: 0.7236\n",
            "Epoch 616/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4719 - accuracy: 0.7719 - val_loss: 0.5116 - val_accuracy: 0.7236\n",
            "Epoch 617/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4718 - accuracy: 0.7658 - val_loss: 0.5113 - val_accuracy: 0.7154\n",
            "Epoch 618/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4718 - accuracy: 0.7699 - val_loss: 0.5114 - val_accuracy: 0.7236\n",
            "Epoch 619/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4713 - accuracy: 0.7658 - val_loss: 0.5110 - val_accuracy: 0.7154\n",
            "Epoch 620/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4711 - accuracy: 0.7719 - val_loss: 0.5110 - val_accuracy: 0.7154\n",
            "Epoch 621/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4707 - accuracy: 0.7719 - val_loss: 0.5108 - val_accuracy: 0.7154\n",
            "Epoch 622/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4704 - accuracy: 0.7699 - val_loss: 0.5107 - val_accuracy: 0.7154\n",
            "Epoch 623/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4704 - accuracy: 0.7719 - val_loss: 0.5107 - val_accuracy: 0.7154\n",
            "Epoch 624/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4704 - accuracy: 0.7699 - val_loss: 0.5107 - val_accuracy: 0.7236\n",
            "Epoch 625/1000\n",
            "491/491 [==============================] - 0s 44us/step - loss: 0.4702 - accuracy: 0.7699 - val_loss: 0.5107 - val_accuracy: 0.7317\n",
            "Epoch 626/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4698 - accuracy: 0.7658 - val_loss: 0.5107 - val_accuracy: 0.7398\n",
            "Epoch 627/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4694 - accuracy: 0.7678 - val_loss: 0.5107 - val_accuracy: 0.7398\n",
            "Epoch 628/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4691 - accuracy: 0.7678 - val_loss: 0.5105 - val_accuracy: 0.7317\n",
            "Epoch 629/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4700 - accuracy: 0.7678 - val_loss: 0.5106 - val_accuracy: 0.7480\n",
            "Epoch 630/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4692 - accuracy: 0.7678 - val_loss: 0.5105 - val_accuracy: 0.7398\n",
            "Epoch 631/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4686 - accuracy: 0.7699 - val_loss: 0.5104 - val_accuracy: 0.7398\n",
            "Epoch 632/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4687 - accuracy: 0.7637 - val_loss: 0.5101 - val_accuracy: 0.7236\n",
            "Epoch 633/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4683 - accuracy: 0.7719 - val_loss: 0.5107 - val_accuracy: 0.7480\n",
            "Epoch 634/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4684 - accuracy: 0.7637 - val_loss: 0.5104 - val_accuracy: 0.7480\n",
            "Epoch 635/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4680 - accuracy: 0.7637 - val_loss: 0.5104 - val_accuracy: 0.7480\n",
            "Epoch 636/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4677 - accuracy: 0.7617 - val_loss: 0.5101 - val_accuracy: 0.7480\n",
            "Epoch 637/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.4673 - accuracy: 0.7678 - val_loss: 0.5101 - val_accuracy: 0.7480\n",
            "Epoch 638/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4676 - accuracy: 0.7678 - val_loss: 0.5100 - val_accuracy: 0.7480\n",
            "Epoch 639/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4673 - accuracy: 0.7699 - val_loss: 0.5098 - val_accuracy: 0.7480\n",
            "Epoch 640/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4668 - accuracy: 0.7658 - val_loss: 0.5095 - val_accuracy: 0.7236\n",
            "Epoch 641/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4674 - accuracy: 0.7678 - val_loss: 0.5097 - val_accuracy: 0.7154\n",
            "Epoch 642/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4675 - accuracy: 0.7699 - val_loss: 0.5096 - val_accuracy: 0.7154\n",
            "Epoch 643/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4669 - accuracy: 0.7719 - val_loss: 0.5094 - val_accuracy: 0.7317\n",
            "Epoch 644/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4668 - accuracy: 0.7719 - val_loss: 0.5096 - val_accuracy: 0.7398\n",
            "Epoch 645/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4660 - accuracy: 0.7719 - val_loss: 0.5103 - val_accuracy: 0.7480\n",
            "Epoch 646/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4660 - accuracy: 0.7637 - val_loss: 0.5095 - val_accuracy: 0.7398\n",
            "Epoch 647/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4657 - accuracy: 0.7699 - val_loss: 0.5096 - val_accuracy: 0.7480\n",
            "Epoch 648/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4656 - accuracy: 0.7699 - val_loss: 0.5095 - val_accuracy: 0.7480\n",
            "Epoch 649/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4656 - accuracy: 0.7637 - val_loss: 0.5093 - val_accuracy: 0.7317\n",
            "Epoch 650/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4655 - accuracy: 0.7658 - val_loss: 0.5093 - val_accuracy: 0.7398\n",
            "Epoch 651/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4655 - accuracy: 0.7699 - val_loss: 0.5095 - val_accuracy: 0.7398\n",
            "Epoch 652/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4661 - accuracy: 0.7658 - val_loss: 0.5094 - val_accuracy: 0.7398\n",
            "Epoch 653/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4653 - accuracy: 0.7678 - val_loss: 0.5093 - val_accuracy: 0.7398\n",
            "Epoch 654/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4645 - accuracy: 0.7719 - val_loss: 0.5093 - val_accuracy: 0.7398\n",
            "Epoch 655/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4645 - accuracy: 0.7658 - val_loss: 0.5093 - val_accuracy: 0.7398\n",
            "Epoch 656/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4643 - accuracy: 0.7658 - val_loss: 0.5092 - val_accuracy: 0.7398\n",
            "Epoch 657/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4645 - accuracy: 0.7719 - val_loss: 0.5090 - val_accuracy: 0.7317\n",
            "Epoch 658/1000\n",
            "491/491 [==============================] - 0s 48us/step - loss: 0.4637 - accuracy: 0.7719 - val_loss: 0.5093 - val_accuracy: 0.7480\n",
            "Epoch 659/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4642 - accuracy: 0.7699 - val_loss: 0.5094 - val_accuracy: 0.7480\n",
            "Epoch 660/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4638 - accuracy: 0.7699 - val_loss: 0.5093 - val_accuracy: 0.7480\n",
            "Epoch 661/1000\n",
            "491/491 [==============================] - 0s 45us/step - loss: 0.4638 - accuracy: 0.7658 - val_loss: 0.5092 - val_accuracy: 0.7480\n",
            "Epoch 662/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4637 - accuracy: 0.7637 - val_loss: 0.5090 - val_accuracy: 0.7317\n",
            "Epoch 663/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4633 - accuracy: 0.7699 - val_loss: 0.5089 - val_accuracy: 0.7398\n",
            "Epoch 664/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4637 - accuracy: 0.7678 - val_loss: 0.5090 - val_accuracy: 0.7480\n",
            "Epoch 665/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4633 - accuracy: 0.7678 - val_loss: 0.5089 - val_accuracy: 0.7398\n",
            "Epoch 666/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4629 - accuracy: 0.7699 - val_loss: 0.5088 - val_accuracy: 0.7317\n",
            "Epoch 667/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4630 - accuracy: 0.7658 - val_loss: 0.5088 - val_accuracy: 0.7398\n",
            "Epoch 668/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4623 - accuracy: 0.7678 - val_loss: 0.5090 - val_accuracy: 0.7480\n",
            "Epoch 669/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4627 - accuracy: 0.7699 - val_loss: 0.5088 - val_accuracy: 0.7480\n",
            "Epoch 670/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4625 - accuracy: 0.7617 - val_loss: 0.5085 - val_accuracy: 0.7317\n",
            "Epoch 671/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4618 - accuracy: 0.7699 - val_loss: 0.5085 - val_accuracy: 0.7317\n",
            "Epoch 672/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4628 - accuracy: 0.7719 - val_loss: 0.5085 - val_accuracy: 0.7398\n",
            "Epoch 673/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4615 - accuracy: 0.7658 - val_loss: 0.5085 - val_accuracy: 0.7317\n",
            "Epoch 674/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4613 - accuracy: 0.7699 - val_loss: 0.5085 - val_accuracy: 0.7317\n",
            "Epoch 675/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4618 - accuracy: 0.7678 - val_loss: 0.5085 - val_accuracy: 0.7398\n",
            "Epoch 676/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4615 - accuracy: 0.7699 - val_loss: 0.5083 - val_accuracy: 0.7317\n",
            "Epoch 677/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4612 - accuracy: 0.7658 - val_loss: 0.5084 - val_accuracy: 0.7317\n",
            "Epoch 678/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4611 - accuracy: 0.7719 - val_loss: 0.5084 - val_accuracy: 0.7398\n",
            "Epoch 679/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4603 - accuracy: 0.7699 - val_loss: 0.5085 - val_accuracy: 0.7480\n",
            "Epoch 680/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4610 - accuracy: 0.7699 - val_loss: 0.5087 - val_accuracy: 0.7480\n",
            "Epoch 681/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4610 - accuracy: 0.7678 - val_loss: 0.5083 - val_accuracy: 0.7398\n",
            "Epoch 682/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4604 - accuracy: 0.7699 - val_loss: 0.5083 - val_accuracy: 0.7398\n",
            "Epoch 683/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4602 - accuracy: 0.7699 - val_loss: 0.5083 - val_accuracy: 0.7398\n",
            "Epoch 684/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4600 - accuracy: 0.7678 - val_loss: 0.5083 - val_accuracy: 0.7398\n",
            "Epoch 685/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4597 - accuracy: 0.7658 - val_loss: 0.5082 - val_accuracy: 0.7398\n",
            "Epoch 686/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4602 - accuracy: 0.7719 - val_loss: 0.5081 - val_accuracy: 0.7398\n",
            "Epoch 687/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4596 - accuracy: 0.7699 - val_loss: 0.5081 - val_accuracy: 0.7398\n",
            "Epoch 688/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4595 - accuracy: 0.7678 - val_loss: 0.5082 - val_accuracy: 0.7398\n",
            "Epoch 689/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.4597 - accuracy: 0.7678 - val_loss: 0.5082 - val_accuracy: 0.7398\n",
            "Epoch 690/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4597 - accuracy: 0.7699 - val_loss: 0.5082 - val_accuracy: 0.7398\n",
            "Epoch 691/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4590 - accuracy: 0.7719 - val_loss: 0.5082 - val_accuracy: 0.7398\n",
            "Epoch 692/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4593 - accuracy: 0.7699 - val_loss: 0.5082 - val_accuracy: 0.7480\n",
            "Epoch 693/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4589 - accuracy: 0.7658 - val_loss: 0.5081 - val_accuracy: 0.7398\n",
            "Epoch 694/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4587 - accuracy: 0.7699 - val_loss: 0.5081 - val_accuracy: 0.7398\n",
            "Epoch 695/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4583 - accuracy: 0.7699 - val_loss: 0.5082 - val_accuracy: 0.7480\n",
            "Epoch 696/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4596 - accuracy: 0.7678 - val_loss: 0.5082 - val_accuracy: 0.7480\n",
            "Epoch 697/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4582 - accuracy: 0.7637 - val_loss: 0.5081 - val_accuracy: 0.7480\n",
            "Epoch 698/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4578 - accuracy: 0.7699 - val_loss: 0.5081 - val_accuracy: 0.7398\n",
            "Epoch 699/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4584 - accuracy: 0.7658 - val_loss: 0.5081 - val_accuracy: 0.7398\n",
            "Epoch 700/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4579 - accuracy: 0.7699 - val_loss: 0.5081 - val_accuracy: 0.7398\n",
            "Epoch 701/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4580 - accuracy: 0.7699 - val_loss: 0.5081 - val_accuracy: 0.7398\n",
            "Epoch 702/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4575 - accuracy: 0.7719 - val_loss: 0.5081 - val_accuracy: 0.7398\n",
            "Epoch 703/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4574 - accuracy: 0.7719 - val_loss: 0.5082 - val_accuracy: 0.7480\n",
            "Epoch 704/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4580 - accuracy: 0.7637 - val_loss: 0.5081 - val_accuracy: 0.7480\n",
            "Epoch 705/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4575 - accuracy: 0.7699 - val_loss: 0.5080 - val_accuracy: 0.7480\n",
            "Epoch 706/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4571 - accuracy: 0.7678 - val_loss: 0.5080 - val_accuracy: 0.7480\n",
            "Epoch 707/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4565 - accuracy: 0.7699 - val_loss: 0.5080 - val_accuracy: 0.7398\n",
            "Epoch 708/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4568 - accuracy: 0.7739 - val_loss: 0.5082 - val_accuracy: 0.7480\n",
            "Epoch 709/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4566 - accuracy: 0.7699 - val_loss: 0.5080 - val_accuracy: 0.7480\n",
            "Epoch 710/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4570 - accuracy: 0.7739 - val_loss: 0.5080 - val_accuracy: 0.7480\n",
            "Epoch 711/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4571 - accuracy: 0.7637 - val_loss: 0.5079 - val_accuracy: 0.7398\n",
            "Epoch 712/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4562 - accuracy: 0.7699 - val_loss: 0.5079 - val_accuracy: 0.7398\n",
            "Epoch 713/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4559 - accuracy: 0.7739 - val_loss: 0.5083 - val_accuracy: 0.7480\n",
            "Epoch 714/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4562 - accuracy: 0.7699 - val_loss: 0.5082 - val_accuracy: 0.7480\n",
            "Epoch 715/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4560 - accuracy: 0.7678 - val_loss: 0.5078 - val_accuracy: 0.7480\n",
            "Epoch 716/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4563 - accuracy: 0.7699 - val_loss: 0.5078 - val_accuracy: 0.7480\n",
            "Epoch 717/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4554 - accuracy: 0.7719 - val_loss: 0.5078 - val_accuracy: 0.7480\n",
            "Epoch 718/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4557 - accuracy: 0.7699 - val_loss: 0.5077 - val_accuracy: 0.7398\n",
            "Epoch 719/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4557 - accuracy: 0.7699 - val_loss: 0.5078 - val_accuracy: 0.7480\n",
            "Epoch 720/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4556 - accuracy: 0.7719 - val_loss: 0.5077 - val_accuracy: 0.7480\n",
            "Epoch 721/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4550 - accuracy: 0.7678 - val_loss: 0.5077 - val_accuracy: 0.7480\n",
            "Epoch 722/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4551 - accuracy: 0.7719 - val_loss: 0.5077 - val_accuracy: 0.7398\n",
            "Epoch 723/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4547 - accuracy: 0.7739 - val_loss: 0.5077 - val_accuracy: 0.7480\n",
            "Epoch 724/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4550 - accuracy: 0.7699 - val_loss: 0.5078 - val_accuracy: 0.7398\n",
            "Epoch 725/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4547 - accuracy: 0.7699 - val_loss: 0.5078 - val_accuracy: 0.7398\n",
            "Epoch 726/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4557 - accuracy: 0.7780 - val_loss: 0.5077 - val_accuracy: 0.7480\n",
            "Epoch 727/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4545 - accuracy: 0.7739 - val_loss: 0.5076 - val_accuracy: 0.7480\n",
            "Epoch 728/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4546 - accuracy: 0.7780 - val_loss: 0.5081 - val_accuracy: 0.7561\n",
            "Epoch 729/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4544 - accuracy: 0.7739 - val_loss: 0.5076 - val_accuracy: 0.7480\n",
            "Epoch 730/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4545 - accuracy: 0.7760 - val_loss: 0.5075 - val_accuracy: 0.7480\n",
            "Epoch 731/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4546 - accuracy: 0.7719 - val_loss: 0.5076 - val_accuracy: 0.7398\n",
            "Epoch 732/1000\n",
            "491/491 [==============================] - 0s 45us/step - loss: 0.4537 - accuracy: 0.7719 - val_loss: 0.5075 - val_accuracy: 0.7480\n",
            "Epoch 733/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4538 - accuracy: 0.7739 - val_loss: 0.5075 - val_accuracy: 0.7480\n",
            "Epoch 734/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4534 - accuracy: 0.7739 - val_loss: 0.5077 - val_accuracy: 0.7398\n",
            "Epoch 735/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4538 - accuracy: 0.7800 - val_loss: 0.5075 - val_accuracy: 0.7398\n",
            "Epoch 736/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4535 - accuracy: 0.7760 - val_loss: 0.5076 - val_accuracy: 0.7398\n",
            "Epoch 737/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4535 - accuracy: 0.7800 - val_loss: 0.5076 - val_accuracy: 0.7398\n",
            "Epoch 738/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4531 - accuracy: 0.7739 - val_loss: 0.5075 - val_accuracy: 0.7480\n",
            "Epoch 739/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4536 - accuracy: 0.7760 - val_loss: 0.5078 - val_accuracy: 0.7398\n",
            "Epoch 740/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4534 - accuracy: 0.7739 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
            "Epoch 741/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4531 - accuracy: 0.7739 - val_loss: 0.5076 - val_accuracy: 0.7398\n",
            "Epoch 742/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4530 - accuracy: 0.7780 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
            "Epoch 743/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4533 - accuracy: 0.7780 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
            "Epoch 744/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4534 - accuracy: 0.7780 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
            "Epoch 745/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4524 - accuracy: 0.7780 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
            "Epoch 746/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4522 - accuracy: 0.7780 - val_loss: 0.5075 - val_accuracy: 0.7398\n",
            "Epoch 747/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4522 - accuracy: 0.7739 - val_loss: 0.5075 - val_accuracy: 0.7398\n",
            "Epoch 748/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4521 - accuracy: 0.7760 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
            "Epoch 749/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4523 - accuracy: 0.7780 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
            "Epoch 750/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4526 - accuracy: 0.7719 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
            "Epoch 751/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4520 - accuracy: 0.7800 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
            "Epoch 752/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4515 - accuracy: 0.7821 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
            "Epoch 753/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4519 - accuracy: 0.7800 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
            "Epoch 754/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4519 - accuracy: 0.7760 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
            "Epoch 755/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4514 - accuracy: 0.7800 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
            "Epoch 756/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4512 - accuracy: 0.7821 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
            "Epoch 757/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4511 - accuracy: 0.7841 - val_loss: 0.5073 - val_accuracy: 0.7398\n",
            "Epoch 758/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4511 - accuracy: 0.7821 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
            "Epoch 759/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4511 - accuracy: 0.7821 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
            "Epoch 760/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4514 - accuracy: 0.7760 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
            "Epoch 761/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4508 - accuracy: 0.7800 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
            "Epoch 762/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4508 - accuracy: 0.7841 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
            "Epoch 763/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4506 - accuracy: 0.7821 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
            "Epoch 764/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4512 - accuracy: 0.7760 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
            "Epoch 765/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4503 - accuracy: 0.7821 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
            "Epoch 766/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4508 - accuracy: 0.7800 - val_loss: 0.5074 - val_accuracy: 0.7398\n",
            "Epoch 767/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4509 - accuracy: 0.7800 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
            "Epoch 768/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4502 - accuracy: 0.7800 - val_loss: 0.5078 - val_accuracy: 0.7398\n",
            "Epoch 769/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4503 - accuracy: 0.7780 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
            "Epoch 770/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4508 - accuracy: 0.7800 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
            "Epoch 771/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4503 - accuracy: 0.7821 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
            "Epoch 772/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4499 - accuracy: 0.7841 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
            "Epoch 773/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4503 - accuracy: 0.7882 - val_loss: 0.5073 - val_accuracy: 0.7398\n",
            "Epoch 774/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4498 - accuracy: 0.7780 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
            "Epoch 775/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4493 - accuracy: 0.7821 - val_loss: 0.5073 - val_accuracy: 0.7398\n",
            "Epoch 776/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4490 - accuracy: 0.7780 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
            "Epoch 777/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4495 - accuracy: 0.7821 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
            "Epoch 778/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4498 - accuracy: 0.7739 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
            "Epoch 779/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4497 - accuracy: 0.7800 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
            "Epoch 780/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4494 - accuracy: 0.7841 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
            "Epoch 781/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4489 - accuracy: 0.7841 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
            "Epoch 782/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4487 - accuracy: 0.7800 - val_loss: 0.5069 - val_accuracy: 0.7480\n",
            "Epoch 783/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4495 - accuracy: 0.7800 - val_loss: 0.5068 - val_accuracy: 0.7480\n",
            "Epoch 784/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4489 - accuracy: 0.7821 - val_loss: 0.5068 - val_accuracy: 0.7480\n",
            "Epoch 785/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4491 - accuracy: 0.7800 - val_loss: 0.5068 - val_accuracy: 0.7480\n",
            "Epoch 786/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4493 - accuracy: 0.7821 - val_loss: 0.5068 - val_accuracy: 0.7480\n",
            "Epoch 787/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4495 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7398\n",
            "Epoch 788/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4483 - accuracy: 0.7841 - val_loss: 0.5074 - val_accuracy: 0.7398\n",
            "Epoch 789/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4482 - accuracy: 0.7862 - val_loss: 0.5068 - val_accuracy: 0.7480\n",
            "Epoch 790/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4484 - accuracy: 0.7841 - val_loss: 0.5070 - val_accuracy: 0.7561\n",
            "Epoch 791/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4485 - accuracy: 0.7882 - val_loss: 0.5075 - val_accuracy: 0.7561\n",
            "Epoch 792/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4479 - accuracy: 0.7841 - val_loss: 0.5069 - val_accuracy: 0.7480\n",
            "Epoch 793/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4484 - accuracy: 0.7862 - val_loss: 0.5067 - val_accuracy: 0.7480\n",
            "Epoch 794/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4484 - accuracy: 0.7862 - val_loss: 0.5068 - val_accuracy: 0.7480\n",
            "Epoch 795/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4476 - accuracy: 0.7841 - val_loss: 0.5068 - val_accuracy: 0.7480\n",
            "Epoch 796/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4474 - accuracy: 0.7882 - val_loss: 0.5068 - val_accuracy: 0.7480\n",
            "Epoch 797/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4474 - accuracy: 0.7780 - val_loss: 0.5069 - val_accuracy: 0.7480\n",
            "Epoch 798/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4480 - accuracy: 0.7841 - val_loss: 0.5067 - val_accuracy: 0.7480\n",
            "Epoch 799/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4471 - accuracy: 0.7862 - val_loss: 0.5068 - val_accuracy: 0.7480\n",
            "Epoch 800/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4469 - accuracy: 0.7862 - val_loss: 0.5067 - val_accuracy: 0.7480\n",
            "Epoch 801/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4471 - accuracy: 0.7902 - val_loss: 0.5067 - val_accuracy: 0.7480\n",
            "Epoch 802/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4479 - accuracy: 0.7862 - val_loss: 0.5070 - val_accuracy: 0.7561\n",
            "Epoch 803/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4471 - accuracy: 0.7841 - val_loss: 0.5068 - val_accuracy: 0.7480\n",
            "Epoch 804/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4465 - accuracy: 0.7902 - val_loss: 0.5068 - val_accuracy: 0.7561\n",
            "Epoch 805/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4466 - accuracy: 0.7882 - val_loss: 0.5068 - val_accuracy: 0.7480\n",
            "Epoch 806/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4463 - accuracy: 0.7862 - val_loss: 0.5071 - val_accuracy: 0.7398\n",
            "Epoch 807/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4469 - accuracy: 0.7841 - val_loss: 0.5069 - val_accuracy: 0.7480\n",
            "Epoch 808/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4467 - accuracy: 0.7821 - val_loss: 0.5071 - val_accuracy: 0.7561\n",
            "Epoch 809/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4462 - accuracy: 0.7862 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
            "Epoch 810/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4468 - accuracy: 0.7862 - val_loss: 0.5070 - val_accuracy: 0.7561\n",
            "Epoch 811/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4464 - accuracy: 0.7841 - val_loss: 0.5071 - val_accuracy: 0.7561\n",
            "Epoch 812/1000\n",
            "491/491 [==============================] - 0s 56us/step - loss: 0.4464 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
            "Epoch 813/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4459 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7561\n",
            "Epoch 814/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4464 - accuracy: 0.7923 - val_loss: 0.5073 - val_accuracy: 0.7561\n",
            "Epoch 815/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4457 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7561\n",
            "Epoch 816/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4465 - accuracy: 0.7862 - val_loss: 0.5072 - val_accuracy: 0.7561\n",
            "Epoch 817/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4459 - accuracy: 0.7882 - val_loss: 0.5076 - val_accuracy: 0.7480\n",
            "Epoch 818/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4458 - accuracy: 0.7882 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
            "Epoch 819/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4463 - accuracy: 0.7902 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
            "Epoch 820/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4457 - accuracy: 0.7923 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
            "Epoch 821/1000\n",
            "491/491 [==============================] - 0s 57us/step - loss: 0.4453 - accuracy: 0.7902 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
            "Epoch 822/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4452 - accuracy: 0.7902 - val_loss: 0.5072 - val_accuracy: 0.7561\n",
            "Epoch 823/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4453 - accuracy: 0.7841 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
            "Epoch 824/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4447 - accuracy: 0.7902 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
            "Epoch 825/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4457 - accuracy: 0.7841 - val_loss: 0.5073 - val_accuracy: 0.7561\n",
            "Epoch 826/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4446 - accuracy: 0.7902 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
            "Epoch 827/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4450 - accuracy: 0.7902 - val_loss: 0.5075 - val_accuracy: 0.7480\n",
            "Epoch 828/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4445 - accuracy: 0.7862 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
            "Epoch 829/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4448 - accuracy: 0.7882 - val_loss: 0.5072 - val_accuracy: 0.7561\n",
            "Epoch 830/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4448 - accuracy: 0.7882 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
            "Epoch 831/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4451 - accuracy: 0.7841 - val_loss: 0.5076 - val_accuracy: 0.7480\n",
            "Epoch 832/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4448 - accuracy: 0.7902 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
            "Epoch 833/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4450 - accuracy: 0.7943 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
            "Epoch 834/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4462 - accuracy: 0.7882 - val_loss: 0.5078 - val_accuracy: 0.7480\n",
            "Epoch 835/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4445 - accuracy: 0.7943 - val_loss: 0.5073 - val_accuracy: 0.7561\n",
            "Epoch 836/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4443 - accuracy: 0.7963 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
            "Epoch 837/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4449 - accuracy: 0.7902 - val_loss: 0.5073 - val_accuracy: 0.7561\n",
            "Epoch 838/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4438 - accuracy: 0.7923 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
            "Epoch 839/1000\n",
            "491/491 [==============================] - 0s 47us/step - loss: 0.4445 - accuracy: 0.7882 - val_loss: 0.5074 - val_accuracy: 0.7561\n",
            "Epoch 840/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4444 - accuracy: 0.7902 - val_loss: 0.5075 - val_accuracy: 0.7480\n",
            "Epoch 841/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4435 - accuracy: 0.7963 - val_loss: 0.5075 - val_accuracy: 0.7561\n",
            "Epoch 842/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4438 - accuracy: 0.7943 - val_loss: 0.5076 - val_accuracy: 0.7480\n",
            "Epoch 843/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4437 - accuracy: 0.7943 - val_loss: 0.5077 - val_accuracy: 0.7480\n",
            "Epoch 844/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4450 - accuracy: 0.7943 - val_loss: 0.5076 - val_accuracy: 0.7561\n",
            "Epoch 845/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4440 - accuracy: 0.7902 - val_loss: 0.5091 - val_accuracy: 0.7398\n",
            "Epoch 846/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4442 - accuracy: 0.7902 - val_loss: 0.5082 - val_accuracy: 0.7480\n",
            "Epoch 847/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4437 - accuracy: 0.7923 - val_loss: 0.5078 - val_accuracy: 0.7480\n",
            "Epoch 848/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4447 - accuracy: 0.7821 - val_loss: 0.5080 - val_accuracy: 0.7480\n",
            "Epoch 849/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4434 - accuracy: 0.7943 - val_loss: 0.5078 - val_accuracy: 0.7561\n",
            "Epoch 850/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4430 - accuracy: 0.7963 - val_loss: 0.5077 - val_accuracy: 0.7561\n",
            "Epoch 851/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4431 - accuracy: 0.7882 - val_loss: 0.5077 - val_accuracy: 0.7561\n",
            "Epoch 852/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4427 - accuracy: 0.7943 - val_loss: 0.5078 - val_accuracy: 0.7561\n",
            "Epoch 853/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4430 - accuracy: 0.7862 - val_loss: 0.5082 - val_accuracy: 0.7480\n",
            "Epoch 854/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4438 - accuracy: 0.7963 - val_loss: 0.5083 - val_accuracy: 0.7480\n",
            "Epoch 855/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4438 - accuracy: 0.7943 - val_loss: 0.5080 - val_accuracy: 0.7561\n",
            "Epoch 856/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4431 - accuracy: 0.7943 - val_loss: 0.5083 - val_accuracy: 0.7480\n",
            "Epoch 857/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4432 - accuracy: 0.7923 - val_loss: 0.5079 - val_accuracy: 0.7561\n",
            "Epoch 858/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4438 - accuracy: 0.7862 - val_loss: 0.5084 - val_accuracy: 0.7480\n",
            "Epoch 859/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4434 - accuracy: 0.7902 - val_loss: 0.5083 - val_accuracy: 0.7480\n",
            "Epoch 860/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4425 - accuracy: 0.7963 - val_loss: 0.5083 - val_accuracy: 0.7561\n",
            "Epoch 861/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4432 - accuracy: 0.7923 - val_loss: 0.5081 - val_accuracy: 0.7480\n",
            "Epoch 862/1000\n",
            "491/491 [==============================] - 0s 44us/step - loss: 0.4424 - accuracy: 0.7902 - val_loss: 0.5081 - val_accuracy: 0.7561\n",
            "Epoch 863/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4428 - accuracy: 0.7923 - val_loss: 0.5089 - val_accuracy: 0.7398\n",
            "Epoch 864/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4423 - accuracy: 0.7963 - val_loss: 0.5081 - val_accuracy: 0.7480\n",
            "Epoch 865/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4429 - accuracy: 0.7902 - val_loss: 0.5081 - val_accuracy: 0.7561\n",
            "Epoch 866/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4423 - accuracy: 0.7963 - val_loss: 0.5083 - val_accuracy: 0.7480\n",
            "Epoch 867/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4429 - accuracy: 0.7943 - val_loss: 0.5083 - val_accuracy: 0.7480\n",
            "Epoch 868/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4423 - accuracy: 0.7902 - val_loss: 0.5086 - val_accuracy: 0.7480\n",
            "Epoch 869/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4419 - accuracy: 0.7923 - val_loss: 0.5083 - val_accuracy: 0.7480\n",
            "Epoch 870/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4415 - accuracy: 0.7943 - val_loss: 0.5083 - val_accuracy: 0.7642\n",
            "Epoch 871/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4431 - accuracy: 0.7923 - val_loss: 0.5084 - val_accuracy: 0.7561\n",
            "Epoch 872/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4422 - accuracy: 0.7902 - val_loss: 0.5086 - val_accuracy: 0.7642\n",
            "Epoch 873/1000\n",
            "491/491 [==============================] - 0s 52us/step - loss: 0.4417 - accuracy: 0.7943 - val_loss: 0.5087 - val_accuracy: 0.7480\n",
            "Epoch 874/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4425 - accuracy: 0.7923 - val_loss: 0.5086 - val_accuracy: 0.7480\n",
            "Epoch 875/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4419 - accuracy: 0.7862 - val_loss: 0.5085 - val_accuracy: 0.7480\n",
            "Epoch 876/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4415 - accuracy: 0.7963 - val_loss: 0.5085 - val_accuracy: 0.7561\n",
            "Epoch 877/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4413 - accuracy: 0.7984 - val_loss: 0.5086 - val_accuracy: 0.7642\n",
            "Epoch 878/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4416 - accuracy: 0.7963 - val_loss: 0.5092 - val_accuracy: 0.7398\n",
            "Epoch 879/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4421 - accuracy: 0.7923 - val_loss: 0.5085 - val_accuracy: 0.7480\n",
            "Epoch 880/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4420 - accuracy: 0.7923 - val_loss: 0.5086 - val_accuracy: 0.7480\n",
            "Epoch 881/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4420 - accuracy: 0.7984 - val_loss: 0.5087 - val_accuracy: 0.7480\n",
            "Epoch 882/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4417 - accuracy: 0.7943 - val_loss: 0.5089 - val_accuracy: 0.7642\n",
            "Epoch 883/1000\n",
            "491/491 [==============================] - 0s 44us/step - loss: 0.4412 - accuracy: 0.7882 - val_loss: 0.5091 - val_accuracy: 0.7561\n",
            "Epoch 884/1000\n",
            "491/491 [==============================] - 0s 45us/step - loss: 0.4417 - accuracy: 0.7963 - val_loss: 0.5088 - val_accuracy: 0.7642\n",
            "Epoch 885/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4414 - accuracy: 0.7984 - val_loss: 0.5088 - val_accuracy: 0.7480\n",
            "Epoch 886/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4419 - accuracy: 0.7943 - val_loss: 0.5092 - val_accuracy: 0.7561\n",
            "Epoch 887/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4408 - accuracy: 0.7963 - val_loss: 0.5089 - val_accuracy: 0.7480\n",
            "Epoch 888/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4410 - accuracy: 0.7943 - val_loss: 0.5090 - val_accuracy: 0.7642\n",
            "Epoch 889/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4408 - accuracy: 0.8024 - val_loss: 0.5090 - val_accuracy: 0.7561\n",
            "Epoch 890/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4420 - accuracy: 0.7943 - val_loss: 0.5089 - val_accuracy: 0.7480\n",
            "Epoch 891/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4419 - accuracy: 0.7862 - val_loss: 0.5091 - val_accuracy: 0.7561\n",
            "Epoch 892/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4411 - accuracy: 0.7963 - val_loss: 0.5090 - val_accuracy: 0.7480\n",
            "Epoch 893/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4404 - accuracy: 0.7963 - val_loss: 0.5091 - val_accuracy: 0.7480\n",
            "Epoch 894/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4408 - accuracy: 0.7984 - val_loss: 0.5093 - val_accuracy: 0.7642\n",
            "Epoch 895/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4411 - accuracy: 0.7902 - val_loss: 0.5093 - val_accuracy: 0.7561\n",
            "Epoch 896/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4415 - accuracy: 0.7984 - val_loss: 0.5092 - val_accuracy: 0.7480\n",
            "Epoch 897/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4411 - accuracy: 0.7963 - val_loss: 0.5096 - val_accuracy: 0.7480\n",
            "Epoch 898/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4406 - accuracy: 0.7963 - val_loss: 0.5092 - val_accuracy: 0.7480\n",
            "Epoch 899/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4402 - accuracy: 0.8004 - val_loss: 0.5093 - val_accuracy: 0.7561\n",
            "Epoch 900/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4406 - accuracy: 0.7963 - val_loss: 0.5093 - val_accuracy: 0.7561\n",
            "Epoch 901/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4401 - accuracy: 0.7923 - val_loss: 0.5096 - val_accuracy: 0.7642\n",
            "Epoch 902/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4401 - accuracy: 0.7984 - val_loss: 0.5095 - val_accuracy: 0.7642\n",
            "Epoch 903/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4407 - accuracy: 0.7984 - val_loss: 0.5098 - val_accuracy: 0.7642\n",
            "Epoch 904/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4414 - accuracy: 0.7902 - val_loss: 0.5094 - val_accuracy: 0.7561\n",
            "Epoch 905/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4403 - accuracy: 0.8004 - val_loss: 0.5098 - val_accuracy: 0.7642\n",
            "Epoch 906/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4410 - accuracy: 0.7984 - val_loss: 0.5097 - val_accuracy: 0.7642\n",
            "Epoch 907/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4404 - accuracy: 0.7963 - val_loss: 0.5094 - val_accuracy: 0.7561\n",
            "Epoch 908/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4396 - accuracy: 0.7984 - val_loss: 0.5096 - val_accuracy: 0.7561\n",
            "Epoch 909/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4402 - accuracy: 0.7963 - val_loss: 0.5095 - val_accuracy: 0.7561\n",
            "Epoch 910/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4401 - accuracy: 0.7984 - val_loss: 0.5098 - val_accuracy: 0.7642\n",
            "Epoch 911/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4398 - accuracy: 0.7984 - val_loss: 0.5097 - val_accuracy: 0.7561\n",
            "Epoch 912/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4403 - accuracy: 0.7923 - val_loss: 0.5096 - val_accuracy: 0.7480\n",
            "Epoch 913/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4397 - accuracy: 0.7923 - val_loss: 0.5101 - val_accuracy: 0.7480\n",
            "Epoch 914/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4395 - accuracy: 0.7984 - val_loss: 0.5097 - val_accuracy: 0.7561\n",
            "Epoch 915/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4400 - accuracy: 0.8024 - val_loss: 0.5098 - val_accuracy: 0.7561\n",
            "Epoch 916/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4413 - accuracy: 0.7963 - val_loss: 0.5097 - val_accuracy: 0.7561\n",
            "Epoch 917/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4394 - accuracy: 0.7943 - val_loss: 0.5105 - val_accuracy: 0.7480\n",
            "Epoch 918/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4397 - accuracy: 0.7963 - val_loss: 0.5098 - val_accuracy: 0.7561\n",
            "Epoch 919/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4393 - accuracy: 0.7984 - val_loss: 0.5099 - val_accuracy: 0.7561\n",
            "Epoch 920/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4387 - accuracy: 0.8004 - val_loss: 0.5103 - val_accuracy: 0.7561\n",
            "Epoch 921/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4390 - accuracy: 0.7984 - val_loss: 0.5099 - val_accuracy: 0.7561\n",
            "Epoch 922/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4391 - accuracy: 0.7963 - val_loss: 0.5101 - val_accuracy: 0.7480\n",
            "Epoch 923/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4391 - accuracy: 0.7943 - val_loss: 0.5100 - val_accuracy: 0.7561\n",
            "Epoch 924/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4398 - accuracy: 0.7923 - val_loss: 0.5100 - val_accuracy: 0.7480\n",
            "Epoch 925/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4393 - accuracy: 0.8004 - val_loss: 0.5100 - val_accuracy: 0.7561\n",
            "Epoch 926/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4388 - accuracy: 0.7943 - val_loss: 0.5101 - val_accuracy: 0.7561\n",
            "Epoch 927/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4384 - accuracy: 0.7984 - val_loss: 0.5101 - val_accuracy: 0.7480\n",
            "Epoch 928/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4396 - accuracy: 0.7984 - val_loss: 0.5102 - val_accuracy: 0.7480\n",
            "Epoch 929/1000\n",
            "491/491 [==============================] - 0s 48us/step - loss: 0.4390 - accuracy: 0.7902 - val_loss: 0.5102 - val_accuracy: 0.7480\n",
            "Epoch 930/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4385 - accuracy: 0.7902 - val_loss: 0.5103 - val_accuracy: 0.7561\n",
            "Epoch 931/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4395 - accuracy: 0.7963 - val_loss: 0.5104 - val_accuracy: 0.7561\n",
            "Epoch 932/1000\n",
            "491/491 [==============================] - 0s 45us/step - loss: 0.4389 - accuracy: 0.8004 - val_loss: 0.5104 - val_accuracy: 0.7480\n",
            "Epoch 933/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4389 - accuracy: 0.7923 - val_loss: 0.5104 - val_accuracy: 0.7480\n",
            "Epoch 934/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4389 - accuracy: 0.7984 - val_loss: 0.5103 - val_accuracy: 0.7561\n",
            "Epoch 935/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4384 - accuracy: 0.7963 - val_loss: 0.5106 - val_accuracy: 0.7480\n",
            "Epoch 936/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4388 - accuracy: 0.7963 - val_loss: 0.5104 - val_accuracy: 0.7480\n",
            "Epoch 937/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4389 - accuracy: 0.7963 - val_loss: 0.5105 - val_accuracy: 0.7561\n",
            "Epoch 938/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4381 - accuracy: 0.7943 - val_loss: 0.5105 - val_accuracy: 0.7561\n",
            "Epoch 939/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4381 - accuracy: 0.8004 - val_loss: 0.5114 - val_accuracy: 0.7480\n",
            "Epoch 940/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4384 - accuracy: 0.7963 - val_loss: 0.5106 - val_accuracy: 0.7480\n",
            "Epoch 941/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4388 - accuracy: 0.7984 - val_loss: 0.5106 - val_accuracy: 0.7480\n",
            "Epoch 942/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4393 - accuracy: 0.7963 - val_loss: 0.5110 - val_accuracy: 0.7561\n",
            "Epoch 943/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4387 - accuracy: 0.8004 - val_loss: 0.5108 - val_accuracy: 0.7480\n",
            "Epoch 944/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4384 - accuracy: 0.7963 - val_loss: 0.5106 - val_accuracy: 0.7480\n",
            "Epoch 945/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4387 - accuracy: 0.8024 - val_loss: 0.5107 - val_accuracy: 0.7480\n",
            "Epoch 946/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4391 - accuracy: 0.7984 - val_loss: 0.5106 - val_accuracy: 0.7480\n",
            "Epoch 947/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4388 - accuracy: 0.7963 - val_loss: 0.5112 - val_accuracy: 0.7480\n",
            "Epoch 948/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4385 - accuracy: 0.7902 - val_loss: 0.5107 - val_accuracy: 0.7480\n",
            "Epoch 949/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4382 - accuracy: 0.7963 - val_loss: 0.5108 - val_accuracy: 0.7480\n",
            "Epoch 950/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4378 - accuracy: 0.7943 - val_loss: 0.5109 - val_accuracy: 0.7480\n",
            "Epoch 951/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4374 - accuracy: 0.7963 - val_loss: 0.5106 - val_accuracy: 0.7561\n",
            "Epoch 952/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4385 - accuracy: 0.8024 - val_loss: 0.5108 - val_accuracy: 0.7480\n",
            "Epoch 953/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4381 - accuracy: 0.7963 - val_loss: 0.5110 - val_accuracy: 0.7480\n",
            "Epoch 954/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4384 - accuracy: 0.7923 - val_loss: 0.5110 - val_accuracy: 0.7561\n",
            "Epoch 955/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4375 - accuracy: 0.7963 - val_loss: 0.5110 - val_accuracy: 0.7480\n",
            "Epoch 956/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4376 - accuracy: 0.7923 - val_loss: 0.5108 - val_accuracy: 0.7561\n",
            "Epoch 957/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4391 - accuracy: 0.7943 - val_loss: 0.5108 - val_accuracy: 0.7561\n",
            "Epoch 958/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4379 - accuracy: 0.7943 - val_loss: 0.5109 - val_accuracy: 0.7561\n",
            "Epoch 959/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4375 - accuracy: 0.7984 - val_loss: 0.5109 - val_accuracy: 0.7561\n",
            "Epoch 960/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4372 - accuracy: 0.8004 - val_loss: 0.5108 - val_accuracy: 0.7561\n",
            "Epoch 961/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4378 - accuracy: 0.8004 - val_loss: 0.5113 - val_accuracy: 0.7561\n",
            "Epoch 962/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4384 - accuracy: 0.7943 - val_loss: 0.5109 - val_accuracy: 0.7480\n",
            "Epoch 963/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4376 - accuracy: 0.7943 - val_loss: 0.5112 - val_accuracy: 0.7724\n",
            "Epoch 964/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4381 - accuracy: 0.7943 - val_loss: 0.5109 - val_accuracy: 0.7561\n",
            "Epoch 965/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4372 - accuracy: 0.8004 - val_loss: 0.5117 - val_accuracy: 0.7480\n",
            "Epoch 966/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4387 - accuracy: 0.7943 - val_loss: 0.5113 - val_accuracy: 0.7480\n",
            "Epoch 967/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4373 - accuracy: 0.7943 - val_loss: 0.5110 - val_accuracy: 0.7561\n",
            "Epoch 968/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4385 - accuracy: 0.7902 - val_loss: 0.5113 - val_accuracy: 0.7480\n",
            "Epoch 969/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4370 - accuracy: 0.8024 - val_loss: 0.5112 - val_accuracy: 0.7561\n",
            "Epoch 970/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4378 - accuracy: 0.7943 - val_loss: 0.5114 - val_accuracy: 0.7480\n",
            "Epoch 971/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4370 - accuracy: 0.7963 - val_loss: 0.5115 - val_accuracy: 0.7480\n",
            "Epoch 972/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4371 - accuracy: 0.7984 - val_loss: 0.5113 - val_accuracy: 0.7561\n",
            "Epoch 973/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4366 - accuracy: 0.7963 - val_loss: 0.5119 - val_accuracy: 0.7480\n",
            "Epoch 974/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4365 - accuracy: 0.7963 - val_loss: 0.5118 - val_accuracy: 0.7480\n",
            "Epoch 975/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4368 - accuracy: 0.7902 - val_loss: 0.5115 - val_accuracy: 0.7480\n",
            "Epoch 976/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4372 - accuracy: 0.7902 - val_loss: 0.5120 - val_accuracy: 0.7480\n",
            "Epoch 977/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4364 - accuracy: 0.7963 - val_loss: 0.5115 - val_accuracy: 0.7561\n",
            "Epoch 978/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4369 - accuracy: 0.7963 - val_loss: 0.5115 - val_accuracy: 0.7561\n",
            "Epoch 979/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4379 - accuracy: 0.7923 - val_loss: 0.5114 - val_accuracy: 0.7561\n",
            "Epoch 980/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4385 - accuracy: 0.7963 - val_loss: 0.5116 - val_accuracy: 0.7561\n",
            "Epoch 981/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4372 - accuracy: 0.7963 - val_loss: 0.5118 - val_accuracy: 0.7480\n",
            "Epoch 982/1000\n",
            "491/491 [==============================] - 0s 50us/step - loss: 0.4374 - accuracy: 0.7902 - val_loss: 0.5119 - val_accuracy: 0.7480\n",
            "Epoch 983/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4371 - accuracy: 0.8004 - val_loss: 0.5122 - val_accuracy: 0.7480\n",
            "Epoch 984/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4368 - accuracy: 0.7963 - val_loss: 0.5121 - val_accuracy: 0.7480\n",
            "Epoch 985/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4363 - accuracy: 0.7963 - val_loss: 0.5117 - val_accuracy: 0.7480\n",
            "Epoch 986/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4360 - accuracy: 0.7963 - val_loss: 0.5119 - val_accuracy: 0.7480\n",
            "Epoch 987/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4377 - accuracy: 0.7923 - val_loss: 0.5117 - val_accuracy: 0.7480\n",
            "Epoch 988/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4367 - accuracy: 0.7984 - val_loss: 0.5116 - val_accuracy: 0.7561\n",
            "Epoch 989/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4375 - accuracy: 0.7963 - val_loss: 0.5120 - val_accuracy: 0.7480\n",
            "Epoch 990/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4367 - accuracy: 0.7923 - val_loss: 0.5130 - val_accuracy: 0.7398\n",
            "Epoch 991/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4367 - accuracy: 0.7963 - val_loss: 0.5122 - val_accuracy: 0.7480\n",
            "Epoch 992/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4369 - accuracy: 0.7984 - val_loss: 0.5118 - val_accuracy: 0.7561\n",
            "Epoch 993/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4362 - accuracy: 0.7984 - val_loss: 0.5120 - val_accuracy: 0.7480\n",
            "Epoch 994/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4359 - accuracy: 0.8004 - val_loss: 0.5121 - val_accuracy: 0.7561\n",
            "Epoch 995/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4379 - accuracy: 0.7984 - val_loss: 0.5123 - val_accuracy: 0.7724\n",
            "Epoch 996/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4366 - accuracy: 0.8004 - val_loss: 0.5121 - val_accuracy: 0.7561\n",
            "Epoch 997/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4358 - accuracy: 0.7963 - val_loss: 0.5129 - val_accuracy: 0.7480\n",
            "Epoch 998/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4358 - accuracy: 0.7943 - val_loss: 0.5123 - val_accuracy: 0.7480\n",
            "Epoch 999/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4359 - accuracy: 0.7963 - val_loss: 0.5126 - val_accuracy: 0.7480\n",
            "Epoch 1000/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4360 - accuracy: 0.7984 - val_loss: 0.5137 - val_accuracy: 0.7480\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ6XKb6Q-_B2",
        "colab_type": "text"
      },
      "source": [
        "Visualize the training loss and validation loss to see if the model is overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRxJtRmP_D-h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "d9518c7e-fe4e-4412-d743-d843e2f488e8"
      },
      "source": [
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJMIVVjF_mQl",
        "colab_type": "text"
      },
      "source": [
        "Visualize the training and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY8zwvA7_pNf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "3fe4b7ae-ad72-4c8d-b381-eaad7c48bb17"
      },
      "source": [
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "plt.legend(['Train', 'Val'], loc='lower right')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQbBR63QAGGo",
        "colab_type": "text"
      },
      "source": [
        "Make a prediction and print the actual values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgUtX86cAKOS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "3f673710-daee-4f8a-e1a7-08bb43ad6264"
      },
      "source": [
        "prediction = model.predict(x_test)\n",
        "prediction = [1 if y >= 0.5 else 0 for y in prediction]\n",
        "\n",
        "print(prediction)\n",
        "print(y_test)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1]\n",
            "[0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1.\n",
            " 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
            " 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X90nEQzVA6PN",
        "colab_type": "text"
      },
      "source": [
        "Evaluate the model on the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3ThjnDBA95j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "b54edbd3-bb3d-4913-cf52-376fb16def4c"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "pred = model.predict(x_train)\n",
        "pred = [1 if y >= 0.5 else 0 for y in pred]\n",
        "\n",
        "print(classification_report(y_train, pred))\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_train, pred))\n",
        "print()\n",
        "print('Accuracy: \\n', accuracy_score(y_train, pred))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.80      0.89      0.84       398\n",
            "         1.0       0.75      0.58      0.66       216\n",
            "\n",
            "    accuracy                           0.79       614\n",
            "   macro avg       0.77      0.74      0.75       614\n",
            "weighted avg       0.78      0.79      0.78       614\n",
            "\n",
            "Confusion Matrix: \n",
            " [[356  42]\n",
            " [ 90 126]]\n",
            "\n",
            "Accuracy: \n",
            " 0.7850162866449512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odjFlX5YCC2R",
        "colab_type": "text"
      },
      "source": [
        "Evaluate the model on the testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9ERtE5iCG9d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "eedee267-befb-452c-80a4-ad68245b0a55"
      },
      "source": [
        "pred = model.predict(x_test)\n",
        "pred = [1 if y >= 0.5 else 0 for y in pred]\n",
        "\n",
        "print(classification_report(y_test, pred))\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, pred))\n",
        "print()\n",
        "print('Accuracy: \\n', accuracy_score(y_test, pred))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.80      0.84      0.82       102\n",
            "         1.0       0.66      0.60      0.63        52\n",
            "\n",
            "    accuracy                           0.76       154\n",
            "   macro avg       0.73      0.72      0.72       154\n",
            "weighted avg       0.76      0.76      0.76       154\n",
            "\n",
            "Confusion Matrix: \n",
            " [[86 16]\n",
            " [21 31]]\n",
            "\n",
            "Accuracy: \n",
            " 0.7597402597402597\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}